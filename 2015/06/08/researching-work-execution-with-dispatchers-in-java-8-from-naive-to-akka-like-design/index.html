
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Concurrent Work Scheduling in Java 8: From Naive to Akka-like Dispatching - Ivan Voroshilin&#8217;s Blog.</title>
  <meta name="author" content="Ivan Voroshilin">

  
  <meta name="description" content="Highly-concurrent dispatchers">

  
  <meta name="keywords" content="Akka, dispatchers, CompletableFuture, Guava, Caffeine, CLHM, cache, ForkJoinPool, WeakReference, Queue, concurrency" />


  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://vibneiro.github.io/2015/06/08/researching-work-execution-with-dispatchers-in-java-8-from-naive-to-akka-like-design/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/octopress/atom.xml" rel="alternate" title="Ivan Voroshilin's Blog." type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-37693662-1', 'ivoroshilin.com');
  ga('send', 'pageview');

</script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Ivan Voroshilin&#8217;s Blog.</a></h1>
  
    <h2>Algorithmic contests, distributed systems and software architecture</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/octopress/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="vibneiro.github.io">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Main page</a></li>
  <li><a href="/blog/archives">All posts</a></li>
  <li><a href="/talks">Talks</a></li>
  <li><a href="/about">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Concurrent Work Scheduling in Java 8: From Naive to Akka-like Dispatching</h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-06-08T22:39:12+03:00'><span class='date'><span class='date-month'>Jun</span> <span class='date-day'>8</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>10:39 pm</span></time>
        
           | <a href="#disqus_thread"
             data-disqus-identifier="http://vibneiro.github.io">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p>Been too long since I last blogged…</p>

<p>Since today, I am changing the format of blogging due to these 2 reasons:</p>

<ol>
<li><p>The blog has moved to the new platform.</p></li>
<li><p>I want to make it more lively and plausible, that is not just writing a problem statement with solutions, but describing chalenges, and the way I came up with smth. So, the text is going to be more hilarious, and easy to follow.. Will see.. ;-)</p></li>
</ol>


<p>Ok, let&rsquo;s catch up.. I’ve been wrestling with concurrent algorithms and scalability lately.
E.g. last month, I was researching design of <a href="https://github.com/akka/akka/blob/master/akka-actor/src/main/scala/akka/dispatch/">Akka Dispatchers</a>,
 advanced caching in java (in particular, a java 8 rewrite of Guava&rsquo;s <a href="https://code.google.com/p/concurrentlinkedhashmap/">ConcurrentLinkedHashMap</a> - <a href="https://github.com/ben-manes/caffeine">«Caffeine»</a>, kudos to Ben Maine for his constant help, he designed both of them btw), did some <a href="https://github.com/vibneiro/dispatching/tree/master/benchmarks-java-8">microbenchmarks</a>.</p>

<h2><strong>TL;DR</strong></h2>

<p>My recent goal was to implement a scalable dispatcher for better throughput in a highly concurrent environment. A dispatcher should be able to schedule asychronously millions of short-living Runnable tasks, coming in from many threads simultaniously. Related tasks should get in the same FIFO submission queue (very much like Actors in Scala and their mailboxes). FIFO property, thereby should ensure that queues&#8217; tasks get executed one-after-another, sequentially, from the same queue. Unrelated task are executed asynchronously.</p>

<p>This post came about as a small research in dispatching in tandem with caching and performance trade-offs.
We&rsquo;re going to touch on some caching techniques in a hashmap&lt;dispatchId, Runnable task>, in particular WeakReference-values (I&rsquo;m going to explain below the reason WeakRerefence on values, odd?), ForkJoinPool magic, ending up with comparison of performance benchmarks.</p>

<h3><strong>Intro</strong></h3>

<p>As been said, there&rsquo;s a Runnable task that needs to be completed. Each such task has a dispatchId.</p>

<p>I originally started exploring pinned to a thread task-dispatching, but then struggled with an overall performance bottleneck..
The first attempt was a <a href="https://github.com/vibneiro/dispatching/blob/master/dispatch-java-8/src/main/java/vibneiro/dispatchers/ThreadBoundHashDispatcher.java">Hashing Dispatcher</a>. That is, there&rsquo;s an array of threads. A hash(dispatchId of task) mod threadsNumber determines a corresponding Thread index in that array, responsible for its execution. Each such thread owns a ConcurrentLinkedQueue as a FIFO-queue, where its gets task and executes them. See the picture for clarity.</p>

<p><img src="https://ivoroshilin.files.wordpress.com/2014/10/threadboundhashdispatcher1.png" alt="" /></p>

<p>As turned out, the algorithm heavily degrades as a number of tasks increases due to the fact that some threads might be idle whereas others are busy. The only advantage might be aimed at low latency, rather than overall performance. If we set up a CPU-affinity (no context switches, locality of CPU-caches is good), provided that tasks are equal in size and more or less uniformly spreaded among thread-buckets, we might benefit from it. But for most application it is not the case. Thus we need another solution.</p>

<h2><strong>Unbalanced work</strong></h2>

<p>What if tasks differ in their execution-time? Some threads can be busy, while others are free.
This leads, as per the above model, to the stall of some threads which is very inefficient, causing unbalanced execution and performance degradation. Even though, if tasks were equal in execution time, that would be a lot less scalable.</p>

<h2><strong>Redesign</strong></h2>

<p>Some dispatchId queues may be more active than the others and unfairly balanced among workers. Thus, we need to somehow decouple a queue from its corresponding thread, but maintain the FIFO order for the same dispatchId. By separating the queue from the worker-thread, we retain FIFO property and more evenly spread out the work - a better throughput!</p>

<p>Let&rsquo;s apply a chained CompletableFuture<task> as a FIFO-queuing mechanism kept in a value of ConcurrentMap&lt;dispatchId, CompletableFuture>. CompletableFuture object can have a reference to the next future for completion, thereby holding a FIFO property. This is like a linked list that forms an execution pipeline.</p>

<p>So, all the work happens in a ConcurrentHashMap which is a cache of tasks for completion. A bit later, I&rsquo;ll show how to integrate this cache with a Dispatcher responsible for scheduling and running tasks from it. For now let&rsquo;s see, how we can efficiently manage eviction of cache&rsquo;s entries.</p>

<p><img src="https://ivoroshilin.files.wordpress.com/2014/10/wsdispatcher.png" alt="" /></p>

<h2><strong>Prunning the cache</strong></h2>

<p>In some usecases, each Runnable task has a unique dispatchId (a global counter might be a good example). Adding a new task to a dispatcher for execution generates a corresponding key for the cache (yes, it is a dispatchId).</p>

<p>If a dispatcher schedules a huge number of incoming tasks, we need to prune the cache (our ConcurrentMap), to avoid OutOfMemory, as there are already completed tasks and their entries can be evicted from it.</p>

<p>WeakReference values can automatically evict CompletabeFuture, based on the observation that the execution chain provides the strong reference and completed futures become a garbage. Why value, but not a key? The key isn&rsquo;t appropriate because it doesn&rsquo;t tells us when its chained CompletedFuture is done. Weak-reference values do! The value has a strong reference through the executor chaining down to the last enqueued future. When the last future completes and is idle, it becomes eligible for garbage collection and the map may evict the entry.</p>

<p>I derived the idea from Guava of prunning the map in a separate thread, right after a cache capacity was reached. This is done with an exclusive tryLock, so that we don&rsquo;t want to block progress of other threads – neat! A thread not being able to capture the lock immediately jumps over to do another work. This reduces the total cost of cache maintenance during dispatching.</p>

<p><img src="https://ivoroshilin.files.wordpress.com/2014/12/weakvaluecorrect.png" alt="" /></p>

<h2>On the cost of Weak-References</h2>

<p>Object allocation is very cheap ~10 cycles compared to ~30 cycles for malloc on most of modern hardware and reclaiming short-lived objects is very cheap.</p>

<p>A lifespan of tasks have an ephemeral nature, so this shouldn&rsquo;t be an issue, as they die in the young space, not being promoted to the old space. The reason behing cheapness is that GC only visits live objects.</p>

<p>The churn rate of tasks is low in most cases, however there is a small GC penalty by delegating the tracking to WeakReference, but can be performed in a minor GC (yes, copying young GC) and aggressively cleared. Because, for most of the applications, the length of the minor GC-pauses is negligible, this is true if most of the objects in Eden can be considered garbage and are never copied to Survivor/Old spaces. If the opposite is true and most of the newborn objects are not eligible for GC, Minor GC pauses start taking considerably more time. In this case, tune you GC appropriately.</p>

<h2>Soft-References - be careful</h2>

<p>Why not SoftReferene values? <a href="http://jeremymanson.blogspot.ru/2009/07/how-hotspot-decides-to-clear_07.html">Soft references require two major GCs</a> in order to be collected, are costly to track, and if abused can fill up the heap to cause GC thrashing. So, they are not appropriate for dispatching.</p>

<h2>Integrating cache with a CompletableFuture</h2>

<p>Here&rsquo;s a simple mechanism that allows to run asyncrhonously tasks via a ConcurrentMap. Please note that for ConcurrentHashMap a new method &ldquo;compute&rdquo; is atomic
and dead-lock-prone, which should be handled with care:</p>

<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">MyConcurrentCache</span><span class="o">.</span><span class="na">compute</span><span class="o">(</span><span class="n">queueName</span><span class="o">,</span> <span class="o">(</span><span class="n">k</span><span class="o">,</span> <span class="n">queue</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="o">{</span>
    <span class="k">return</span> <span class="o">(</span><span class="n">queue</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span>
        <span class="o">?</span> <span class="n">CompletableFuture</span><span class="o">.</span><span class="na">runAsync</span><span class="o">(</span><span class="n">task</span><span class="o">)</span>
        <span class="o">:</span> <span class="n">queue</span><span class="o">.</span><span class="na">thenRunAsync</span><span class="o">(</span><span class="n">task</span><span class="o">);</span></code></pre></div>


<p>This is a gist!</p>

<h2><strong>Thread Pool - a big deal</strong></h2>

<p>≈A few words about <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinPool.html">ForkJoinPool</a> and non-recursive tasks. Many people still tend to think that ForkJoinPool is efficient only for Recursive tasks. I <a href="http://stackoverflow.com/questions/30047122/java-forkjoinpool-with-non-recursive-tasks-does-work-stealing-work">asked this question</a> a while ago on stackoverflow and even had to ask Alexey Shipilev for help. Why does <a href="http://akka.io/">Akka</a> use ForkJoinPool as the main engine of task execution? Or why does JDK 8 take advantage of a commonPool() in its Streaming and CompletedFuture implementations?
Fork/Join is the default parallel computation framework since Java 8. For short tasks, which don&rsquo;t involve heavy I/O, ForkJoinPool is a way more scalable, unlike e.g. FixedThreadPool!
JMH benchmarks depict this <a href="https://github.com/vibneiro/dispatching">very clearly</a>. Tasks are already small and needn&rsquo;t a recursive decomposition. Work-stealing works (read the design of ForkJoinPool, if confused), regardless whether it is a big or small task - tasks can be grabbed by another free worker from the Deque&rsquo;s tail of a busy worker, reducing contention drastically.</p>

<p>Don&rsquo;t be surprised that in the graphs below for JDK 7/8 results are very different. <a href="http://openjdk.java.net/jeps/155">These are the changes</a> targetted at JDK 8, thus the difference. Both improvements for ForkJoinPool (up to 60x speedup!) and cache-oriented enhancements to the ConcurrentHashMap made this possible.
The idea is to treat external submitters in a similar way as workers — using randomized queuing and stealing. This also greatly improves throughput when all tasks are async and submitted to the pool rather than forked, which becomes a reasonable way to structure actor frameworks, as well as many plain services that you might otherwise use ThreadPoolExecutor for. This was not true in JDK 7, where I observed a lot of overhead in many cases with FJ.</p>

<p>As a result, ForkJoinPool matches dispatcher&rsquo;s requirements perfrectly, being able of accepting asynchronous tasks returning you a Future object. Moreover <a href="https://jcp.org/en/jsr/detail?id=166">JSR-166</a> says that new features include support for completion-based designs that are often most appropriate for IO-bound usages, among others. But, I didn&rsquo;t check with the I/O..</p>

<h2><strong>Akka Actors and dispatching framework : Differences in the design approach</strong></h2>

<p>There are <a href="http://doc.akka.io/docs/akka/2.3.7/scala/dispatchers.html">4 different dispatchers</a> in the Akka framework.</p>

<p>Our WorkStealingDispatcher is similar to an <a href="https://github.com/akka/akka/blob/master/akka-actor/src/main/scala/akka/dispatch/BalancingDispatcher.scala">Akka BalancingDispatcher</a> by:</p>

<ul>
<li>A shared queue (caching CHM, bear in mind though Akka&rsquo;s queue has a different data structure)</li>
<li>A concept of work-stealing.</li>
</ul>


<p>But there is a difference. My framework doesn&rsquo;t know anything about actors (thus no concept of mailboxes and other related stuff). Moreover,
caching techniques described here is just another requirement that is absent in the standard Akka implementation for clear reasons.</p>

<p>Akka invariant:
 - All actors can process all messages that have been sent to one of the actors via &ldquo;work stealing&rdquo; (to be more specific &ldquo;work donating&rdquo;).</p>

<p>Our invariant:
 - All threads can process all messages that have been sent to one of the dispatchId via &ldquo;work stealing&rdquo;.</p>

<p>Their PinnedDispatcher is like our ThreadBoundHashDispatcher again in the concept, but design differs. :-)
It dedicates a single unique thread for each actor passed in as reference.</p>

<p>To prevent visibility and reordering problems on actors, Akka guarantees the following two &ldquo;happens before&rdquo; rules:
 1. The actor send rule: the send of the message to an actor happens before the receive of that message by the same actor.
 2. The actor subsequent processing rule: processing of one message happens before processing of the next message by the same actor.</p>

<p>My framework makes these guarantess too.
 1. The dispatchId send rule: the send of the message to a dispatchId happens before the receive of that message by the same dispatchId.
 Proof:
   - WorkStealingDispatcher: CHM hash-bucket locks and volatile reads ensure safe publication and happens-before guarantees;
   - ThreadBoundHashDispatcher: ConcurrentLinkedHashMap locks ensure safe publication and happens-before guarantees;
 2. The dispatchId subsequent processing rule: processing of one message happens before processing of the next message by the same dispatchID.
 Proof:
   - WorkStealingDispatcher: ConcurrentHashMap.compute is atomic by the contract and CompletableFuture&rsquo;s ordered chain ensures this;
   - ThreadBoundHashDispatcher: Java&rsquo;s ConcurrentLinkedHashMap ensures this;</p>

<h2><strong>At last, the microbenchmarks</strong></h2>

<p>Benchmarks were written on JMH framework for JDK 7 and 8 separately and run on iMac Core i5 CPU @ 2.50GHz (4 cores) 8 GB, Yosemite OS. All the benchmark work with an empty Runnable synthetic task to mitigate side-effects.</p>

<p>I&rsquo;ve attached here 2 graphs for comparison of performance of JDK 7 and JDK 8 algorithms, respectively, based on random dispatchIds over a finite set.
For more thorough analysis, see <a href="https://github.com/vibneiro/dispatching/blob/master/README.md">the Dispatch Benchmarks on Github</a>. The trends don&rsquo;t differ much from test to test within a single Java-version, which proves eviction overhead (Bounded caching) of Weak-values to be neglible for these tests.</p>

<p><strong>Tests for Benchmarking:</strong></p>

<ol>
<li>A single dispatch-queue: putting new tasks always to the same dispatchId.</li>
<li>Counting dispatchId: one-off queue of size = 1 per task, that is dispatchId is incremented by 1 for new task.</li>
<li>Randomly filled set of queues with a size = 32768.</li>
</ol>


<p><strong>Benchmarking details:</strong></p>

<ul>
<li> Measuring a throughput (ops/s)</li>
<li> 32 user threads for all 3 tests;

<ul>
<li>Purpose: analyze contention impact on concurrent data-structures.</li>
</ul>
</li>
<li> 2 types of ExecutorService { ThreadPoolExecutor, ForkJoinPool };

<ul>
<li>Purpose: analyze the impact of 2 different executors on throughput.</li>
</ul>
</li>
</ul>


<p><strong>Caffeine</strong>
JDK 8 benchmarks have an additional test with Caffeinated cache which is a robust data structure that won my benchmarking tests, and can be used in the dispatching as well.</p>

<p><strong>JDK 8: 1.8.0_45</strong></p>

<p><img src="https://cloud.githubusercontent.com/assets/3040823/8034389/e25c08fc-0def-11e5-84dd-b95140376a46.png" alt="1. Java Version: 1.8.0_45" /></p>

<p><strong>JDK 7: 1.7.0._71</strong></p>

<p><img src="https://cloud.githubusercontent.com/assets/3040823/8080802/2c58486a-0f78-11e5-9e69-cb505e8df29d.png" alt="2. Java Version: 1.7.0_71" /></p>

<p>Note: A Caffeine works with JDK 8+, so there&rsquo;s no its benchmark here.</p>

<p><strong>Results: </strong></p>

<p>As can be seen, after introducing significant <a href="http://openjdk.java.net/jeps/155">updates</a> to Java 8, ForkJoinPool is a way more scalable, including ConcurrentHashMap changes compared to JDK 7.</p>

<h2>Conclusion</h2>

<p>I studied some parts of Caffeine&rsquo;s cache design under the hood. There are advanced techniques (e.g. eventually-consistent multithreaded datastructures, Stripe64 and full rewrite of ConcurrentHashMap proves to be very efficient)! It was fun to make some research, I believe it definetely deserves another post.</p>

<p>It showed very good results on the majority of <a href="https://github.com/vibneiro/dispatching">JMH performance benchmarks</a> compared to my implementations under similar parameters, considering working weak-values.
I decided not to remove <a href="https://github.com/vibneiro/dispatching/blob/master/dispatch-java-8/src/main/java/vibneiro/dispatchers/ThreadBoundHashDispatcher.java">ThreadBoundHashDispatcher</a> from the code though, as one might potentially have some benefits for some rare cases.</p>

<p>See <a href="https://github.com/vibneiro/dispatching">the code on Github</a> for more research, if interested.</p>

<p>By the way! Here&rsquo;s <a href="https://github.com/vibneiro/dispatching/blob/master/dispatch-java-7/src/main/java/vibneiro/dispatchers/WorkStealingDispatcher.java">a backport of Dispatcher to JDK 7</a> translated with Guava&rsquo;s ListenableFuture. I needed it for my project, despite that JDK 7 is not supported officialy anymore.</p>

<p>Hope this helps,</p>

<p>Ivan</p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">vibneiro</span></span>

      




<time class='entry-date' datetime='2015-06-08T22:39:12+03:00'><span class='date'><span class='date-month'>Jun</span> <span class='date-day'>8</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>10:39 pm</span></time>
      

<span class="categories">
  
    <a class='category' href='/categories/algorithms/'>algorithms</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/2015/03/13/migrated-to-octopress/" title="Previous Post: The blog has migrated to a new platform "Octopress"">&laquo; The blog has migrated to a new platform &#8220;Octopress&#8221;</a>
      
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Welcome to my blog</h1>
  <script src="//about.me/embed/ivan_voroshilin?headline=0"></script>

</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/2015/06/08/researching-work-execution-with-dispatchers-in-java-8-from-naive-to-akka-like-design/">Concurrent Work Scheduling in Java 8: From Naive to Akka-like Dispatching</a>
      </li>
    
      <li class="post">
        <a href="/2015/03/13/migrated-to-octopress/">The Blog Has Migrated to a New Platform &#8220;Octopress&#8221;</a>
      </li>
    
      <li class="post">
        <a href="/2015/02/05/toughest-backtracking-problems-in-algorithmic-competitions/">Toughest Backtracking Problems in Algorithmic Competitions</a>
      </li>
    
      <li class="post">
        <a href="/2014/12/16/docker-creating-and-testing-httprest-server-on-top-of-akkaspray/">Dockerizing Spray HTTP Server</a>
      </li>
    
      <li class="post">
        <a href="/2014/10/30/docker-a-birds-eye-view/">Docker: A Bird&#8217;s-eye View</a>
      </li>
    
      <li class="post">
        <a href="/2014/10/12/the-flip-side-of-rule-engines-and-some-tips-on-when-not-use-ones/">The Flip Side of Rule Engines on Example of Drools and Some Valuable Tips</a>
      </li>
    
      <li class="post">
        <a href="/2014/09/15/project-euler-a-list-of-interesting-problems/">Project Euler: A List of Interesting Problems</a>
      </li>
    
      <li class="post">
        <a href="/2014/08/14/command-and-query-responsibility-segregation-and-event-sourcing-what-you-should-think-about-in-advance/">Command and Query Responsibility Segregation and Event Sourcing: What You Should Think About in Advance</a>
      </li>
    
      <li class="post">
        <a href="/2014/03/18/distributed-transactions-and-scalability-issues-in-large-scale-distributed-systems/">Distributed Transactions and Scalability Issues in Large-scale Distributed Systems</a>
      </li>
    
      <li class="post">
        <a href="/2014/02/17/service-discovery-in-distributed-systems/">Service Discovery in Distributed Systems</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'vibneiro',
            count: 10,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Ivan Voroshilin
</p>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-37693662-1', 'ivoroshilin.com');
  ga('send', 'pageview');

</script>


</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'vibneiro';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://vibneiro.github.io/2015/06/08/researching-work-execution-with-dispatchers-in-java-8-from-naive-to-akka-like-design/';
        var disqus_url = 'http://vibneiro.github.io/2015/06/08/researching-work-execution-with-dispatchers-in-java-8-from-naive-to-akka-like-design/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>









<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-37693662-1', 'ivoroshilin.com');
  ga('send', 'pageview');

</script>






</body>
</html>
