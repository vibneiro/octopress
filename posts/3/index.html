
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Ivan Voroshilin&#8217;s Blog.</title>
  <meta name="author" content="Ivan Voroshilin">

  
  <meta name="description" content="Today I was lucky to have attended the annual developers conference HighLoad++ 2013. This is the 7-th time. Some conference sessions are translated &hellip;">

  
  <meta name="keywords" content="distributed, algorithm, Ivan, Voroshilin, code, google, jam, software, architecture, geek, blog" />


  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://vibneiro.github.io/posts/3/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/octopress/atom.xml" rel="alternate" title="Ivan Voroshilin's Blog." type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37693662-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Ivan Voroshilin&#8217;s Blog.</a></h1>
  
    <h2>Algorithmic contests, distributed systems and software architecture</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/octopress/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="vibneiro.github.io">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2013/10/29/highload-conference-2013/">HighLoad Conference 2013</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2013-10-29T21:24:32+04:00'><span class='date'><span class='date-month'>Oct</span> <span class='date-day'>29</span><span class='date-suffix'>th</span>, <span class='date-year'>2013</span></span> <span class='time'>9:24 pm</span></time>
        
           | <a href="/2013/10/29/highload-conference-2013/#disqus_thread"
             data-disqus-identifier="http://vibneiro.github.io/2013/10/29/highload-conference-2013/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Today I was lucky to have attended the annual developers conference <a href="http://www.highload.ru">HighLoad++</a> 2013. This is the 7-th time. Some conference sessions are translated into English and available here: <a href="http://www.highload.co/freeonline/">http://www.highload.co/freeonline/</a></p>

<p><a href="http://ivoroshilin.files.wordpress.com/2013/10/pa293662.jpg"><img src="http://ivoroshilin.files.wordpress.com/2013/10/pa293662.jpg?w=300" alt="OLYMPUS DIGITAL CAMERA" /></a></p>

<p>Listeners heard many buzzwords like horizontal scalability, replication, sharding and NoSql. Despite that I missed the first day of the conference what I really liked was not just new trends in technology but invaluable speakers&#8217; experience  on real projects with pros and cons, especially:</p>

<ol>
<li> <strong>&ldquo;MySql versus something else&rdquo;</strong> by <strong>Mark Callaghan [FaceBook]</strong> on storage efficiency, framework for analysis and benchmarking and database algorithms: <a href="https://www.facebook.com/MySQLatFacebook">https://www.facebook.com/MySQLatFacebook</a></li>
</ol>


<p><a href="http://ivoroshilin.files.wordpress.com/2013/10/pa293677.jpg"><img src="http://ivoroshilin.files.wordpress.com/2013/10/pa293677.jpg" alt="PA293677" /></a></p>

<ol>
<li><p><strong>&ldquo;Cassandra vs In-Memory Data Grid in eCommerce&rdquo;</strong> by <strong>Alexander Soloviev  [Grid Dynamics]</strong> was very informative on deep analysis and benchmarking against different cases and their pros and cons.</p></li>
<li><p><strong>&ldquo;Query Optimizer in MariaDB: now w/o indices&#8221; </strong>by <strong>Sergey Golubchik [Monty Program Ab]</strong></p></li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2013/10/07/minhash-algorithm-or-how-to-quickly-find-similarities-among-2-documents/">MinHash Algorithm or How to Quickly Find Similarities Among 2 Documents</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2013-10-07T02:57:48+04:00'><span class='date'><span class='date-month'>Oct</span> <span class='date-day'>7</span><span class='date-suffix'>th</span>, <span class='date-year'>2013</span></span> <span class='time'>2:57 am</span></time>
        
           | <a href="/2013/10/07/minhash-algorithm-or-how-to-quickly-find-similarities-among-2-documents/#disqus_thread"
             data-disqus-identifier="http://vibneiro.github.io/2013/10/07/minhash-algorithm-or-how-to-quickly-find-similarities-among-2-documents/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>MinHash is a technique from <a href="http://en.wikipedia.org/wiki/Locality_sensitive_hashing">Locality Sensitive Hashing</a> allowing to find similarities among 2 sets. This is a  buzzword frequently met in Data Mining  and Data Science fields of CS. What surprising is that this method was invented in 1997 and used in <a href="http://en.wikipedia.org/wiki/AltaVista">AltaVista</a> web-search engine back in the 90s to find similarities among web-documents and it also can be used to:</p>

<ul>
<li><p>Find duplicates</p></li>
<li><p>Near duplicate image detection</p></li>
<li><p>Near neighbor search</p></li>
</ul>


<p>Basically the algorithm can be applied to anything that can be presented by numbers.</p>

<p>Let&rsquo;s start with a bit of math from theory of probability and statistics.</p>

<p>Define a formula of two sets <em>A</em> and <em>B:</em></p>

<p><img src="http://upload.wikimedia.org/math/1/8/6/186c7f4e83da32e889d606140fae25a0.png" alt=" J(A,B) = |A \cap B|\over|A \cup B|." /></p>

<p>This is so-called  a <a href="http://en.wikipedia.org/wiki/Jaccard_index">Jaccard coefficient</a>.</p>

<p>Where: J ∈ [0..1]</p>

<p>j = 0 - if <em><em><em>A</em> ∩ </em>B = 0, that is 2 sets are disjoint meaning there are no similarities</em></p>

<p><em>j = 1 - if __A</em> ∩ <em>B</em> = A = <em>B, that is 2 sets are identical.</em>
__</p>

<p>A, B are more similar when their <strong>Jaccard coefficient</strong> is closer to 1.</p>

<p>This simple formula is cumbersome if the sets are quite large, e.g. 2 web-documents of more than 1MB in size. Ouch, that&rsquo;s too much. 1MB of text-data is <strong>1,048,576 characters </strong>provided that 1 ASCII char = 8 bits (of course for unicode charset it is greater).</p>

<p>Now that we understand a bit of theory let&rsquo;s try to apply hashing to Jaccard coefficient. Everywhere I hear hashing it always leads to randomized algorithms.</p>

<p>Ok, let&rsquo;s move on. The main idea is that similar objects hash to the same bucket. This follows from the fact that <strong>probability of collision higher for similar objects</strong>.</p>

<p>Here we give an example for 2 sets A and B but the algorithm can be applied to any number of sets.</p>

<ol>
<li><p>Essentially, we need to construct a set of independent hash functions &lt;h1,h2,h3,&hellip;hk> <strong>randomly</strong>.  <em>k</em> = O(1/ε2), ε > 0 such that the expected error of the estimate is at most ε. For example, 400 hashes would be required to estimate <em>J</em>(<em>A</em>,<em>B</em>) with an expected error less than or equal to .05. So, k can be varied to increase/decrease the likelihood of false negatives.</p></li>
<li><p>Next we initialize for each set A and B the <img src="http://www.toao.com/equations/49e83e4884bd478aecc7fb7e0a7e9477.png" alt="" /> value to infinity.</p></li>
<li><p>For each element s in both sets A and B we compute the element&rsquo;s hash:</p></li>
</ol>


<p><img src="http://www.toao.com/equations/8664800335406d60ca14c723421d994c.png" alt="" /> such as: If <img src="http://www.toao.com/equations/d3d634b0636790f7fd707ad50b85b0a5.png" alt="" /> then <img src="http://www.toao.com/equations/f08914f853c4fcd405dafd052d100c5a.png" alt="" />.</p>

<p>Eventually we should have <img src="http://www.toao.com/equations/49e83e4884bd478aecc7fb7e0a7e9477.png" alt="" /> for both sets A and B.</p>

<ol>
<li><p>If 2 sets A and B are similar then the probability P(  <img src="http://www.toao.com/equations/49e83e4884bd478aecc7fb7e0a7e9477.png" alt="" />A =  <img src="http://www.toao.com/equations/49e83e4884bd478aecc7fb7e0a7e9477.png" alt="" />B) = |<em>A</em> ∩ <em>B</em>| / |A U B|- is high and <strong>it</strong> <strong>is the actual Jaccard coefficient!</strong></p></li>
<li><p>We calculated  <img src="http://www.toao.com/equations/49e83e4884bd478aecc7fb7e0a7e9477.png" alt="" /> statistics to estimate how similar are these 2 sets. General formula is: Similarity = identical <img src="http://www.toao.com/equations/49e83e4884bd478aecc7fb7e0a7e9477.png" alt="" />s / k</p></li>
</ol>


<p>In real world this requires considering more thoroughly different parameters, hash-functions etc. However, to demonstrate the algorithm I wrote a simple java code:</p>

<p>[sourcecode language=&ldquo;java&rdquo;]
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.Random;
import java.util.Set;</p>

<p>public class LSHMinHash<T> {</p>

<pre><code>private final int hashes[];
private final int numOfHashes;
private final int numOfSets;
private final Set&lt;T&gt; setA;
private final Set&lt;T&gt; setB;
private final Map&lt;T, boolean[]&gt; matrix;
private final int[][] minHashes;

public LSHMinHash(double e, Set&lt;T&gt; setA, Set&lt;T&gt; setB){
    this.numOfHashes = (int)(1 / (e * e));
    this.numOfSets = 2;
    this.setA = setA;
    this.setB = setB;
    matrix = buildSetMatrix(setA, setB);
    minHashes = initMinHashes(numOfSets, numOfHashes);
    hashes = computeHashes(numOfHashes);
}

private Map&lt;T,boolean[]&gt; buildSetMatrix(Set&lt;T&gt; setA, Set&lt;T&gt; setB) {

    Map&lt;T,boolean[]&gt; matrix = new HashMap&lt;T,boolean[]&gt;();

    for(T element : setA){
        matrix.put(element, new boolean[] { true, false } );
    }

    for(T element : setB){
        if(matrix.containsKey(element)){
            matrix.put(element, new boolean[] { true, true } );
        }else if(!matrix.containsKey(element)){
            matrix.put(element, new boolean[] { false, true } );
        }
    }

    return matrix;
}

private int[][] initMinHashes(int numOfSets, int numOfHashes) {
    int[][] minHashes = new int[numOfSets][numOfHashes];

    for (int i = 0; i &lt; numOfSets; i++) {
        for (int j = 0; j &lt; numOfHashes; j++) {
            minHashes[i][j] = Integer.MAX_VALUE;
        }
    }
    return minHashes;
}

private int[] computeHashes(int numOfHashes) {
    int[] hashes = new int[numOfHashes];
    Random r = new Random(31);

    for (int i = 0; i &lt; numOfHashes; i++){
        int a = (int)r.nextInt();
        int b = (int)r.nextInt();
        int c = (int)r.nextInt();
        hashes[i] = (int)((a * (a * b * c &gt;&gt; 4) + a * a * b * c + c) &amp; 0xFFFFFFFF);
    }
    return hashes;
}

private void computeMinHashForSet(Set&lt;T&gt; set, int setIndex){
    int hashIndex = 0;

    for(T element : matrix.keySet()) {
        for (int i = 0; i &lt; numOfHashes; i++) {
            if(set.contains(element)) {
                int hashValue = hashes[hashIndex];
                if (hashValue &lt; minHashes[setIndex][hashIndex]) {
                    minHashes[setIndex][hashIndex] = hashValue;
                }
            }
        }
        hashIndex++;
    }
}

private double computeMinHash(int[][] minHashes, int numOfHashes) {
    int identicalMinHashes = 0;
    for (int i = 0; i &lt; numOfHashes; i++){
        if (minHashes[0][i] == minHashes[1][i]) {
            identicalMinHashes++;
        }
    }
    return (1.0 * identicalMinHashes) / numOfHashes;
}

public double findSimilarities() {
    computeMinHashForSet(setA, 0);
    computeMinHashForSet(setB, 1);
    return computeMinHash(minHashes, numOfHashes);
}

public static void main(String[] args){
    Set&lt;String&gt; setA = new HashSet&lt;String&gt;();
    setA.add("THIS");
    setA.add("IS ");
    setA.add("THE");
    setA.add("CASE");

    Set&lt;String&gt; setB = new HashSet&lt;String&gt;();
    setB.add("THAT");
    setB.add("IS ");
    setB.add("THE");
    setB.add("CASE");

    double errorFactor = 0.001;

    LSHMinHash&lt;String&gt; minHash = new LSHMinHash&lt;String&gt;(errorFactor, setA, setB);
    System.out.println(minHash.findSimilarities());
}
</code></pre>

<p>}
[/sourcecode]</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2013/09/11/google-code-jam-qualification-round-2013-problem-d-treasure/">Google Code Jam. Qualification Round 2013. Problem D - Treasure. Solved.</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2013-09-11T18:34:59+04:00'><span class='date'><span class='date-month'>Sep</span> <span class='date-day'>11</span><span class='date-suffix'>th</span>, <span class='date-year'>2013</span></span> <span class='time'>6:34 pm</span></time>
        
           | <a href="/2013/09/11/google-code-jam-qualification-round-2013-problem-d-treasure/#disqus_thread"
             data-disqus-identifier="http://vibneiro.github.io/2013/09/11/google-code-jam-qualification-round-2013-problem-d-treasure/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://ivoroshilin.files.wordpress.com/2013/09/1.jpg"><img src="http://ivoroshilin.files.wordpress.com/2013/09/1.jpg" alt="1" /></a></p>

<p>This was <a href="https://code.google.com/codejam/contest/2270488/dashboard#s=p3&amp;a=3">the problem</a> I wasn&rsquo;t able to optimise with given time constraint in April.  Later I killed half a day to complete it thinking of different algorithms from the graph theory such as Eulerian path
and Chinese postman problems. I was surprised at that time this problem was put into qualification round as it is really challenging. In order to solve one the graph problem should be refined and modeled properly. During modeling a graph I used to always map only one type of entity to vertices.  As a counter-example a <a href="http://en.wikipedia.org/wiki/Bipartite_graph">Bipartite graph</a> has vertices which are divided into two disjoint sets U and V such that every edge connects a vertex in U to one in V. The solution to this one has nothing to do with Bipartite graph attacking approaches except that there are 2 types of vertices.</p>

<h2><strong>The solution</strong></h2>

<p><strong>1. Check that the number of chests matches the number of corresponding key types</strong>. A simple arithmetic to count. Otherwise there is no solution as we don&rsquo;t have enough keys to open all chests.</p>

<p><strong>2. All vertices in a graph G should be reachable from vertex v0.</strong></p>

<p>Construct a directed graph G=(V,E), where K is a set of all keys and C is a set of all chests:</p>

<ul>
<li><p>V = {K} U {C} U {0}.</p></li>
<li><p>{0} = v0 is a starting vertex corresponding to the root vertex. Outgoing edges from it are key(s) given us initially.</p></li>
<li><p>E = {Set of all directed edges connecting K and C}. (i,j) ∈ E if either {i=chest, j=key} or {i=key, j=chest}</p></li>
</ul>


<p>In simple words we have a directed graph where each vertex is either a chest or a key, directed edges form a  connection in between. We need to check that there&rsquo;s a directed path between vertex v0 and every other vertex ∈ E, otherwise we cannot open all chests and solution is impossible. Note that we need to check directed paths to all key-vertices from v0. This is a standard <a href="http://en.wikipedia.org/wiki/Reachability">single-source reachability</a> and can be done applying a<a href="http://en.wikipedia.org/wiki/Depth-first_search"> Depth-First-Search</a> algorithm:</p>

<p>[sourcecode language=&ldquo;java&rdquo;]
void dfs(Graph g, int v) {
marked[v] = true;
for (int w : g.adj(v)) {
if (!marked[w]) dfs(G, w);
}
 }
[/sourcecode]</p>

<p>Technically, if there are unmarked vertices, the problem is unsolvable. Time complexity is O(E+V). This check cuts lots of branches saving us time.</p>

<p>Now let&rsquo;s demonstrate the above on a real example. Our treasure trove consists of four chests, and you began with exactly one key of type 1.</p>

<p>See the table with input data:</p>

<pre><code>Chest Number  |  Key Type To Open Chest  |  Key Types Inside
--------------+--------------------------+------------------
1             |  1                       |  None
2             |  1                       |  1, 3
3             |  2                       |  None
4             |  3                       |  2
</code></pre>

<p>Let&rsquo;s draw a graph where v0 is a staring point of traversal (i.e. initial key of type = 1)</p>

<p><a href="http://ivoroshilin.files.wordpress.com/2013/09/graph.jpg"><img src="http://ivoroshilin.files.wordpress.com/2013/09/graph.jpg" alt="graph" /></a></p>

<p>As depicted there are 2 solvable configurations - &lt;2,1,4,3> and &lt;2,4,3,1>. All paths from v0 to the keys are reachable. The proof of this condition can done by induction and left to the reader.</p>

<p><strong>3. Find a &ldquo;lexicographically smallest&rdquo; solution.</strong> This last condition added real hardness to the problem. If there are multiple solutions then we find a &ldquo;lexicographically smallest&rdquo; way to open the boxes. Each vertex is always traversed from lowest to highest, this can be achieved by constructing a graph using adjacency lists that reflect numbers of keys and chests in increasing order and we subsequently iterate them applying a bit optimized Depth-First-Search. Minimal configuration starts from v0. If we have  >= 1 key initially given, we just have to traverse from all of them increasingly. On each step we always update a number of keys in possession. If we&rsquo;ve run out of keys then we cut the branch and backtrack, starting again where we left off with the next configuration. E.g. opening a chest No. 1 at the very first time will lead to the deadlock (actually this one is a trivial case as it is on step No 1). Such cases are not on critical path and we need backtrack only to the previous calling vertex.</p>

<p><strong>Conclusion:</strong> There are not so many configurations unlike straightforward brute force. Many optimization problems like this one are met in algorithmic contests. Just algorithms and data structures are not sufficient. To pass given time constraint there should be the right strategy to cut unsolvable branches. That&rsquo;s it!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2013/07/15/distributed-caching-under-consistent-hashing/">How Automatic Sharding Works or Consistent Hashing Under the Hood</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2013-07-15T12:25:09+04:00'><span class='date'><span class='date-month'>Jul</span> <span class='date-day'>15</span><span class='date-suffix'>th</span>, <span class='date-year'>2013</span></span> <span class='time'>12:25 pm</span></time>
        
           | <a href="/2013/07/15/distributed-caching-under-consistent-hashing/#disqus_thread"
             data-disqus-identifier="http://vibneiro.github.io/2013/07/15/distributed-caching-under-consistent-hashing/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Preface</h2>

<p>Here we&rsquo;re going to talk primarily about Consistent hashing. This technique involves such concepts as adaptive load balancing, routing, partitioning in distributed computing. There are many articles on the internet on this technique (refer to the list of references for some of them) but I haven&rsquo;t found information about how and where to keep the ring of hashes, thus I&rsquo;ve decided to describe some options with pros and cons. In order to make this post more clear for a wider audience I will first try to write a brief introduction of what this is all about and tell about <strong>the ring storage strategies</strong> at the end of this issue. So if you&rsquo;re already familiar with the algorithm you may want to skip over the main stuff and move on to the last chapter for pros and cons of descibed approaces.</p>

<h3>Distributed cache and straightforward uniform load balancing</h3>

<p>Key-value stores are extremely fast in single search-queries. A very popular one is a distributed hash table (DHT) kept in a fully decentralized manner, and thus particularly adapted to unstable networks where nodes can leave or join at any moment. Note that DHT is not suitable for range-queries albeit and I will probably write a separate post about special data structures responsible for that. Now let&rsquo;s consider a classic case - you have a cluster of cache-servers where you load-balance a huge data set uniformly. To be able to determine on which node a pair &lt;key, value> should be kept we use a simple hash-mapping:</p>

<blockquote>Cache machine = hash(o) mod n where: n - number of machines in a cluster and o is an object to put/lookup.</blockquote>


<p>What happens when a number of machines changes at runtime? You might add/remove a number of machines in a cluster for e.g. scalability reasons, a failure or whatever.  The change triggers moving almost all objects to new locations due to rehashing.  Each key-value pair will get reallocated completely across the cluster. You’ll end up moving a fraction<strong> n/(n+1)</strong> of your data to new machines. Indeed, this fact degrades all of the advantages of distributed hash tables. We need somehow to avoid this messy remapping. This is where consistent hashing comes in.</p>

<h2>Consistent hashing</h2>

<p>The main idea is to hash both data ids and cache-machines to a numeric range using the same hash-function. E.g. in Java a primitive type int has a number range of values between -231 to 231-1.  Assume the interval is [0,  231-1] for simplicity (java primitives cannot be unsigned). Now let&rsquo;s join starting and ending points together of this interval to create a ring so the values wrap around. We do not have 231 -1 available servers, the large size of the ring being merely intended to avoid collisions. As a hash function a good choise is either be e.g. MD5 or SHA-1 algorithm. As a machine&rsquo;s number we can take its IP-address and apply that hash function to it. By taking from the result the first 8 bytes we can map it to our ring [0,231-1].</p>

<p><a href="http://ivoroshilin.files.wordpress.com/2013/07/ring_range1.png"><img src="http://ivoroshilin.files.wordpress.com/2013/07/ring_range1.png" alt="ring_range" /></a></p>

<p>Both the nodes and the keys are mapped to the same range on the ring. Ok, now we need to understand how to identify on this ring which data ids belong to which server&rsquo;s IP. It&rsquo;s really simple, we just move clockwise starting from zero (starting point on the ring) following the main rule of consistent hashing: If IP-n1 and IP-n2 are 2 adjacent nodes on the ring all data ids on the ring between them belong to IP-n1. That&rsquo;s it. <a href="http://ivoroshilin.files.wordpress.com/2013/07/ring_mapping1.png"><img src="http://ivoroshilin.files.wordpress.com/2013/07/ring_mapping1.png" alt="ring_mapping" /></a></p>

<p>As depicted: { Id1, Id2, Id3} ∈ IP-3; {Id4} ∈ IP-1; ∅ ∈ IP-2.</p>

<p><strong>Conclusion:</strong> Using consistent hashing we do not need to rehash the whole data set. Instead, the new server takes place at a position determined by the hash value on the ring, and part of the objects stored on its successor must be moved. The reorganization is local, as all the other nodes remain unaffected. if you add a machine to the cluster, only the data that needs to live on that machine is moved there; all the other data stays where it is. Because the hash function remains unaffected, the scheme maintains its consistency over the successive evolutions of the network configuration. Like naive hashing, consistent hashing spreads the distributed dictionary almost evenly across the cluster. One point to mention is what happens when a node goes down due to some disaster. In this case consistent hashing alone doesn&rsquo;t meet our requirements of reliability due to loss of data. Therefore there should definetely be replication and high availability which is feasible and out of scope of this introduction. You may want to find good references at the end of these article to find out more.</p>

<h3>Problems with pure consistent hashing</h3>

<p>In a nutshell, the basic consistent hashing has the following problems:</p>

<ul>
<li><p>There is a huge amount of data to be rehashed.</p></li>
<li><p>A node picking a range of keys results in one node potentially carrying a larger keyspace than others, therefore still creating disbalance.</p></li>
<li><p>Leaving/Joining a ring leads to disbalance of data.</p></li>
<li><p>A more powerful machine needs to process more data than others.</p></li>
<li><p>A fraction of data to be moved is less unpredictable and much higher.</p></li>
</ul>


<p><strong>Virtual nodes </strong>solve these issues.</p>

<h2>Virtual nodes come to the rescue</h2>

<p>Virtual nodes <strong>minimize changes</strong> <strong>to a node&rsquo;s assigned range</strong> by a number of smaller ranges to a single node. In other words, amount of data to be moved from one physical node to others is minimized. Let&rsquo;s split a real node into a number of virtual nodes. The idea is to build equally-sized subintervals (partitions) for each real server on the ring by dividing the hash-space into P evenly sized partitions, and assign P/N partitions per host. When a node joins/leaves all data from partitions of all real servers are uniformly get assigned to a new server and given back to remaining ones respectively. The number of virtual nodes is picked once during building of the ring  and never changes over the lifetime of the cluster. This ensures that each node picks equal size of data from the full data set, that is P/N and thus our data now are distributed more uniformly. This enforces that the number of virtual nodes must be much higher than the number of real ones.</p>

<p><a href="http://ivoroshilin.files.wordpress.com/2013/07/ring_hashing.png"><img src="http://ivoroshilin.files.wordpress.com/2013/07/ring_hashing.png" alt="ring_hashing" /></a></p>

<p>Here&rsquo;s a pretty simple java-code of consistency ring&rsquo;s  with virtual nodes.</p>

<p>[sourcecode language=&ldquo;java&rdquo;]
public class Ring {</p>

<pre><code>private SortedMap&lt;Long, T&gt; ring = new TreeMap&lt;Long, T&gt;();
private HashMap&lt;String, T&gt; nodeMap = new HashMap&lt;String, T&gt;();
private MD5Hash hash = new MD5Hash();
private vNodeCount;

public Ring(int vnodeCount, Collection pNodes) {

    this.vnodeCount = vnodeCount;

    for (T pNode : pNodes) {
        addNode(ring, nodeMap, pNode, vnodeCount);
    }
}

private void addNode(T pNode, int vnodeCount) {
    for (int i = 0; i &lt; vnodeCount; i++) {
        ring.put(hash.hash(pNode.toString() + i), pNode);
    }
}

    public void removeNode(T node, int vnodeCount) {
      for (int i = 0; i &lt; vnodeCount; i++) {
        ring.remove(hash.hash(pNode.toString() + i));
      }
    }

private T getNodeByObjectId(String objectId) {

    long hashValue = hash.hash(objectId);

    if (!ring.containsKey(hashValue)) {
        SortedMap&lt;Long, T&gt; tailMap = ring.tailMap(hashValue);
        hashValue = tailMap.isEmpty() ? ring.firstKey() : tailMap.firstKey();
    }

    return ring.get(hashValue);
}

private static class MD5Hash {
    MessageDigest instance;

    public MD5Hash() {
        try {
            instance = MessageDigest.getInstance("MD5");
        } catch (NoSuchAlgorithmException e) {
        }
    }

    long hash(String key) {
        instance.reset();
        instance.update(key.getBytes());
        byte[] digest = instance.digest();

        long h = 0;
        for (int i = 0; i &lt; 4; i++) {
            h &lt;&lt;= 8;
            h |= ((int) digest[i]) &amp; 0xFF;
        }
        return h;
    }
};
</code></pre>

<p>}
[/sourcecode]</p>

<h2>Strategies to keep a data structure of the ring and their pros and cons</h2>

<p>There are a few options on where to keep ring&rsquo;s data structure:</p>

<ul>
<li><p><strong>Central point of coordination:</strong> A dedicated machine keeps a ring and works as a <strong>central load-balancer</strong> which routes request to appropriate nodes.</p></li>
<li><p>Pros: Very simple implementation. This would be a good fit for not a dynamic system having small number of nodes and/or data.</p></li>
<li><p>Cons: A big drawback of this approach is scalability and reliability. Stable distributed systems don&rsquo;t have a <strong>single poing of failure.</strong></p></li>
<li><p><strong><strong>No central point of coordination - full duplication:</strong> </strong>Each node keeps a full copy of the ring. Applicable for stable networks. This option is used e.g. in Amazon Dynamo.</p></li>
<li><p>Pros: Queries are routed in one hop directly to the appropriate cache-server.</p></li>
<li><p>Cons: Join/Leave of a server from the ring  requires notification/amendment of all cache-servers in the ring.</p></li>
<li><p><strong>No central point of coordination - partial duplication: </strong>Each node keeps a partial copy of the ring. This option is direct implementation of CHORD algorithm. In terms of DHT each cache-machine has its predessesor and successor and when receiving a query one checks if it has the key or not. If there&rsquo;s no such a key on that machine, a mapping function is used to determine which of its neighbors (successor and predessesor) has the least distance to that key. Then it forwards the query to its neighbor thas has the least distance. The process continues until a current cache-machine finds the key and sends it back.</p></li>
<li><p>Pros: For highly dynamic changes the previous option is not a fit due to heavy overhead of gossiping among nodes. Thus this option is the choice in this case.</p></li>
<li><p>Cons: No direct routing of messages. The complexity of routing a message to the destination node in a ring is O(lg N).</p></li>
</ul>


<h3>Current trends in consistent hashing</h3>

<p>There is a huge boom nowadays of new products that implement this technique. Some of them are: Dynamo, Riak, Cassandra, MemCached, Voldemort, CouchDB, Oracle Coherence, Trackerless Bit-Torrent networks, Web-caching frameworks, Content distribution networks.</p>

<h2>References</h2>

<ul>
<li><p><a href="http://java.dzone.com/articles/simple-magic-consistent">The Simple Magic of Consistent Hashing</a></p></li>
<li><p><a href="http://michaelnielsen.org/blog/consistent-hashing/">Consistent hashing</a></p></li>
<li><p><a href="https://weblogs.java.net/blog/tomwhite/archive/2007/11/consistent_hash.html">Consistent hashing by Tom White</a></p></li>
<li><p><a href="http://techspot.zzzeek.org/2012/07/07/the-absolutely-simplest-consistent-hashing-example">The Absolutely Simplest Consistent Hashing Example</a></p></li>
<li><p><a href="http://cloudfundoo.wordpress.com/2012/05/28/distributed-hash-tables-and-consistent-hashing/">Distributed Hash Tables and Consistent Hashing</a></p></li>
<li><p><a href="http://www.acunu.com/2/post/2012/07/virtual-nodes-strategies.html">Virtual Nodes strategies</a> <a href="http://www.tomkleinpeter.com/2008/03/17/programmers-toolbox-part-3-consistent-hashing/">Programmer&rsquo;s toolbox</a></p></li>
<li><p><a href="http://www.tomkleinpeter.com/2008/03/17/programmers-toolbox-part-3-consistent-hashing/">Programmer&rsquo;s toolbox: consistent hashing</a></p></li>
<li><p><a href="http://offthelip.org/?p=149">Distributed Hash Tables</a></p></li>
<li><p><a href="http://www.lastfm.ru/user/RJ/journal/2007/04/10/rz_libketama_-_a_consistent_hashing_algo_for_memcache_clients">libketama - a consistent hashing algo for memcache clients</a></p></li>
<li><p><a href="http://www.sarmady.com/siamak/papers/dht-soft-300807.pdf">A Peer-to-Peer Dictionary Using Chord DHT</a></p></li>
<li><p><a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf">Dynamo: Amazon’s Highly Available Key-value Store</a></p></li>
<li><p><a href="http://greg.brim.net/page/building_a_consistent_hashing_ring.html">Building a Consistent Hashing Ring</a></p></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2013/04/23/java-one-2013/">Annual Conference Java One 2013</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2013-04-23T18:57:31+04:00'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>23</span><span class='date-suffix'>rd</span>, <span class='date-year'>2013</span></span> <span class='time'>6:57 pm</span></time>
        
           | <a href="/2013/04/23/java-one-2013/#disqus_thread"
             data-disqus-identifier="http://vibneiro.github.io/2013/04/23/java-one-2013/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://ivoroshilin.files.wordpress.com/2013/04/javaone2013.jpg"><img src="http://ivoroshilin.files.wordpress.com/2013/04/javaone2013.jpg" alt="javaone2013" /></a></p>

<p>Java One 2013, Moscow</p>

<p>Today is the first day of annual conference &ldquo;Java One 2013&rdquo; At Crocus Expo, Moscow Russia. Sponsors are as follows: Deutsche bank, Luxoft, odnoklassniki.ru and several other companies.</p>

<p>Traditionally the conference lasts for 2 days with 94 sessions and 65 speakers around the world. Some of them are from the previous year. On the whole the venue and organizations is better this year and the plan has really interesting sessions on modern buzzwords nowadays like Scala, Cloud space and distributed caches.</p>

<p><a href="http://www.oracle.com/javaone/ru-en/index.html">http://www.oracle.com/javaone/ru-en/index.html</a></p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/4">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/posts/2">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Welcome to my blog</h1>
  <script src="//about.me/embed/ivan_voroshilin?headline=0"></script>

</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/2015/03/13/migrated-to-octopress/">The Blog Has Migrated to a New Platform</a>
      </li>
    
      <li class="post">
        <a href="/2015/03/04/review-of-service-discovery-solutions/">Service Discovery Solutions in Distributed Systems</a>
      </li>
    
      <li class="post">
        <a href="/2015/02/05/toughest-backtracking-problems-in-algorithmic-competitions/">Toughest Backtracking Problems in Algorithmic Competitions</a>
      </li>
    
      <li class="post">
        <a href="/2014/12/16/docker-creating-and-testing-httprest-server-on-top-of-akkaspray/">Dockerizing Spray HTTP Server</a>
      </li>
    
      <li class="post">
        <a href="/2014/10/30/docker-a-birds-eye-view/">Docker: A Bird&#8217;s-eye View</a>
      </li>
    
      <li class="post">
        <a href="/2014/10/12/the-flip-side-of-rule-engines-and-some-tips-on-when-not-use-ones/">The Flip Side of Rule Engines on Example of Drools and Some Valuable Tips</a>
      </li>
    
      <li class="post">
        <a href="/2014/09/15/project-euler-a-list-of-interesting-problems/">Project Euler: A List of Interesting Problems</a>
      </li>
    
      <li class="post">
        <a href="/2014/08/14/command-and-query-responsibility-segregation-and-event-sourcing-what-you-should-think-about-in-advance/">Command and Query Responsibility Segregation and Event Sourcing: What You Should Think About in Advance</a>
      </li>
    
      <li class="post">
        <a href="/2014/03/18/distributed-transactions-and-scalability-issues-in-large-scale-distributed-systems/">Distributed Transactions and Scalability Issues in Large-scale Distributed Systems</a>
      </li>
    
      <li class="post">
        <a href="/2014/02/17/service-discovery-in-distributed-systems/">Service Discovery in Distributed Systems</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'vibneiro',
            count: 10,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Ivan Voroshilin -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>


  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37693662-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'vibneiro';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
