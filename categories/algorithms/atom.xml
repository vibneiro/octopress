<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Algorithms | Ivan Voroshilin's Blog.]]></title>
  <link href="http://vibneiro.github.io/categories/algorithms/atom.xml" rel="self"/>
  <link href="http://vibneiro.github.io/"/>
  <updated>2015-06-23T23:47:25+03:00</updated>
  <id>http://vibneiro.github.io/</id>
  <author>
    <name><![CDATA[Ivan Voroshilin]]></name>
    <email><![CDATA[mail@ivoroshilin.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Concurrent Work Scheduling in Java 8: From Naive to Akka-like Dispatching]]></title>
    <link href="http://vibneiro.github.io/2015/06/08/researching-work-execution-with-dispatchers-in-java-8-from-naive-to-akka-like-design/"/>
    <updated>2015-06-08T22:39:12+03:00</updated>
    <id>http://vibneiro.github.io/2015/06/08/researching-work-execution-with-dispatchers-in-java-8-from-naive-to-akka-like-design</id>
    <content type="html"><![CDATA[<p>Been too long since I last blogged…</p>

<p>Since today, I am changing the format of blogging due to these 2 reasons:</p>

<ol>
<li><p>The blog has moved to the new platform.</p></li>
<li><p>I want to make it more lively and plausible, that is not just writing a problem statement with solutions, but describing chalenges, and the way I came up with smth. So, the text is going to be more hilarious, and easy to follow.. Will see.. ;-)</p></li>
</ol>


<p>Ok, let&rsquo;s catch up.. I’ve been wrestling with concurrent algorithms and scalability lately.
E.g. last month, I was researching design of <a href="https://github.com/akka/akka/blob/master/akka-actor/src/main/scala/akka/dispatch/">Akka Dispatchers</a>,
 advanced caching in java (in particular, a java 8 rewrite of Guava&rsquo;s <a href="https://code.google.com/p/concurrentlinkedhashmap/">ConcurrentLinkedHashMap</a> - <a href="https://github.com/ben-manes/caffeine">«Caffeine»</a>, kudos to Ben Maine for his constant help, he designed both of them btw), did some <a href="https://github.com/vibneiro/dispatching/tree/master/benchmarks-java-8">microbenchmarks</a>.</p>

<h2><strong>TL;DR</strong></h2>

<p>My recent goal was to implement a scalable dispatcher for better throughput in a highly concurrent environment. A dispatcher should be able to schedule asychronously millions of short-living Runnable tasks, coming in from many threads simultaniously. Related tasks should get in the same FIFO submission queue (very much like Actors in Scala and their mailboxes). FIFO property, thereby should ensure that queues&#8217; tasks get executed one-after-another, sequentially, from the same queue. Unrelated task are executed asynchronously.</p>

<p>This post came about as a small research in dispatching in tandem with caching and performance trade-offs.
We&rsquo;re going to touch on some caching techniques in a hashmap&lt;dispatchId, Runnable task>, in particular WeakReference-values (I&rsquo;m going to explain below the reason WeakRerefence on values, odd?), ForkJoinPool magic, ending up with comparison of performance benchmarks.</p>

<h3><strong>Intro</strong></h3>

<p>As been said, there&rsquo;s a Runnable task that needs to be completed. Each such task has a dispatchId.</p>

<p>I originally started exploring pinned to a thread task-dispatching, but then struggled with an overall performance bottleneck..
The first attempt was a <a href="https://github.com/vibneiro/dispatching/blob/master/dispatch-java-8/src/main/java/vibneiro/dispatchers/ThreadBoundHashDispatcher.java">Hashing Dispatcher</a>. That is, there&rsquo;s an array of threads. A hash(dispatchId of task) mod threadsNumber determines a corresponding Thread index in that array, responsible for its execution. Each such thread owns a ConcurrentLinkedQueue as a FIFO-queue, where its gets task and executes them. See the picture for clarity.</p>

<p><img src="https://ivoroshilin.files.wordpress.com/2014/10/threadboundhashdispatcher1.png" alt="" /></p>

<p>As turned out, the algorithm heavily degrades as a number of tasks increases due to the fact that some threads might be idle whereas others are busy. The only advantage might be aimed at low latency, rather than overall performance. If we set up a CPU-affinity (no context switches, locality of CPU-caches is good), provided that tasks are equal in size and more or less uniformly spreaded among thread-buckets, we might benefit from it. But for most application it is not the case. Thus we need another solution.</p>

<h2><strong>Unbalanced work</strong></h2>

<p>What if tasks differ in their execution-time? Some threads can be busy, while others are free.
This leads, as per the above model, to the stall of some threads which is very inefficient, causing unbalanced execution and performance degradation. Even though, if tasks were equal in execution time, that would be a lot less scalable.</p>

<h2><strong>Redesign</strong></h2>

<p>Some dispatchId queues may be more active than the others and unfairly balanced among workers. Thus, we need to somehow decouple a queue from its corresponding thread, but maintain the FIFO order for the same dispatchId. By separating the queue from the worker-thread, we retain FIFO property and more evenly spread out the work - a better throughput!</p>

<p>Let&rsquo;s apply a chained CompletableFuture<task> as a FIFO-queuing mechanism kept in a value of ConcurrentMap&lt;dispatchId, CompletableFuture>. CompletableFuture object can have a reference to the next future for completion, thereby holding a FIFO property. This is like a linked list that forms an execution pipeline.</p>

<p>So, all the work happens in a ConcurrentHashMap which is a cache of tasks for completion. A bit later, I&rsquo;ll show how to integrate this cache with a Dispatcher responsible for scheduling and running tasks from it. For now let&rsquo;s see, how we can efficiently manage eviction of cache&rsquo;s entries.</p>

<p><img src="https://ivoroshilin.files.wordpress.com/2014/10/wsdispatcher.png" alt="" /></p>

<h2><strong>Prunning the cache</strong></h2>

<p>In some usecases, each Runnable task has a unique dispatchId (a global counter might be a good example). Adding a new task to a dispatcher for execution generates a corresponding key for the cache (yes, it is a dispatchId).</p>

<p>If a dispatcher schedules a huge number of incoming tasks, we need to prune the cache (our ConcurrentMap), to avoid OutOfMemory, as there are already completed tasks and their entries can be evicted from it.</p>

<p>WeakReference values can automatically evict CompletabeFuture, based on the observation that the execution chain provides the strong reference and completed futures become a garbage. Why value, but not a key? The key isn&rsquo;t appropriate because it doesn&rsquo;t tells us when its chained CompletedFuture is done. Weak-reference values do! The value has a strong reference through the executor chaining down to the last enqueued future. When the last future completes and is idle, it becomes eligible for garbage collection and the map may evict the entry.</p>

<p>I derived the idea from Guava of prunning the map in a separate thread, right after a cache capacity was reached. This is done with an exclusive tryLock, so that we don&rsquo;t want to block progress of other threads – neat! A thread not being able to capture the lock immediately jumps over to do another work. This reduces the total cost of cache maintenance during dispatching.</p>

<p><img src="https://ivoroshilin.files.wordpress.com/2014/12/weakvaluecorrect.png" alt="" /></p>

<h2>On the cost of Weak-References</h2>

<p>Object allocation is very cheap ~10 cycles compared to ~30 cycles for malloc on most of modern hardware and reclaiming short-lived objects is very cheap.</p>

<p>A lifespan of tasks have an ephemeral nature, so this shouldn&rsquo;t be an issue, as they die in the young space, not being promoted to the old space. The reason behing cheapness is that GC only visits live objects.</p>

<p>The churn rate of tasks is low in most cases, however there is a small GC penalty by delegating the tracking to WeakReference, but can be performed in a minor GC (yes, copying young GC) and aggressively cleared. Because, for most of the applications, the length of the minor GC-pauses is negligible, this is true if most of the objects in Eden can be considered garbage and are never copied to Survivor/Old spaces. If the opposite is true and most of the newborn objects are not eligible for GC, Minor GC pauses start taking considerably more time. In this case, tune you GC appropriately.</p>

<h2>Soft-References - be careful</h2>

<p>Why not SoftReferene values? <a href="http://jeremymanson.blogspot.ru/2009/07/how-hotspot-decides-to-clear_07.html">Soft references require two major GCs</a> in order to be collected, are costly to track, and if abused can fill up the heap to cause GC thrashing. So, they are not appropriate for dispatching.</p>

<h2>Integrating cache with a CompletableFuture</h2>

<p>Here&rsquo;s a simple mechanism that allows to run asyncrhonously tasks via a ConcurrentMap. Please note that for ConcurrentHashMap a new method &ldquo;compute&rdquo; is atomic
and dead-lock-prone, which should be handled with care:</p>

<p><div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">MyConcurrentCache</span><span class="o">.</span><span class="na">compute</span><span class="o">(</span><span class="n">queueName</span><span class="o">,</span> <span class="o">(</span><span class="n">k</span><span class="o">,</span> <span class="n">queue</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="o">{</span>
    <span class="k">return</span> <span class="o">(</span><span class="n">queue</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span>
        <span class="o">?</span> <span class="n">CompletableFuture</span><span class="o">.</span><span class="na">runAsync</span><span class="o">(</span><span class="n">task</span><span class="o">)</span>
        <span class="o">:</span> <span class="n">queue</span><span class="o">.</span><span class="na">thenRunAsync</span><span class="o">(</span><span class="n">task</span><span class="o">);</span></code></pre></div></p>

<p>This is a gist!</p>

<h2><strong>Thread Pool - a big deal</strong></h2>

<p>≈A few words about <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinPool.html">ForkJoinPool</a> and non-recursive tasks. Many people still tend to think that ForkJoinPool is efficient only for Recursive tasks. I <a href="http://stackoverflow.com/questions/30047122/java-forkjoinpool-with-non-recursive-tasks-does-work-stealing-work">asked this question</a> a while ago on stackoverflow and even had to ask Alexey Shipilev for help. Why does <a href="http://akka.io/">Akka</a> use ForkJoinPool as the main engine of task execution? Or why does JDK 8 take advantage of a commonPool() in its Streaming and CompletedFuture implementations?
Fork/Join is the default parallel computation framework since Java 8. For short tasks, which don&rsquo;t involve heavy I/O, ForkJoinPool is a way more scalable, unlike e.g. FixedThreadPool!
JMH benchmarks depict this <a href="https://github.com/vibneiro/dispatching">very clearly</a>. Tasks are already small and needn&rsquo;t a recursive decomposition. Work-stealing works (read the design of ForkJoinPool, if confused), regardless whether it is a big or small task - tasks can be grabbed by another free worker from the Deque&rsquo;s tail of a busy worker, reducing contention drastically.</p>

<p>Don&rsquo;t be surprised that in the graphs below for JDK 7/8 results are very different. <a href="http://openjdk.java.net/jeps/155">These are the changes</a> targetted at JDK 8, thus the difference. Both improvements for ForkJoinPool (up to 60x speedup!) and cache-oriented enhancements to the ConcurrentHashMap made this possible.
The idea is to treat external submitters in a similar way as workers — using randomized queuing and stealing. This also greatly improves throughput when all tasks are async and submitted to the pool rather than forked, which becomes a reasonable way to structure actor frameworks, as well as many plain services that you might otherwise use ThreadPoolExecutor for. This was not true in JDK 7, where I observed a lot of overhead in many cases with FJ.</p>

<p>As a result, ForkJoinPool matches dispatcher&rsquo;s requirements perfrectly, being able of accepting asynchronous tasks returning you a Future object. Moreover <a href="https://jcp.org/en/jsr/detail?id=166">JSR-166</a> says that new features include support for completion-based designs that are often most appropriate for IO-bound usages, among others. But, I didn&rsquo;t check with the I/O..</p>

<h2><strong>Akka Actors and dispatching framework : Differences in the design approach</strong></h2>

<p>There are <a href="http://doc.akka.io/docs/akka/2.3.7/scala/dispatchers.html">4 different dispatchers</a> in the Akka framework.</p>

<p>Our WorkStealingDispatcher is similar to an <a href="https://github.com/akka/akka/blob/master/akka-actor/src/main/scala/akka/dispatch/BalancingDispatcher.scala">Akka BalancingDispatcher</a> by:</p>

<ul>
<li>A shared queue (caching CHM, bear in mind though Akka&rsquo;s queue has a different data structure)</li>
<li>A concept of work-stealing.</li>
</ul>


<p>But there is a difference. My framework doesn&rsquo;t know anything about actors (thus no concept of mailboxes and other related stuff). Moreover,
caching techniques described here is just another requirement that is absent in the standard Akka implementation for clear reasons.</p>

<p>Akka invariant:</p>

<ul>
<li>All actors can process all messages that have been sent to one of the actors via &ldquo;work stealing&rdquo; (to be more specific &ldquo;work donating&rdquo;).</li>
</ul>


<p>Our invariant:</p>

<ul>
<li>All threads can process all messages that have been sent to one of the dispatchId via &ldquo;work stealing&rdquo;.</li>
</ul>


<p>Their PinnedDispatcher is like our ThreadBoundHashDispatcher again in the concept, but design differs. :-)
It dedicates a single unique thread for each actor passed in as reference.</p>

<p>To prevent visibility and reordering problems on actors, Akka guarantees the following two &ldquo;happens before&rdquo; rules:</p>

<ol>
<li>The actor send rule: the send of the message to an actor happens before the receive of that message by the same actor.</li>
<li>The actor subsequent processing rule: processing of one message happens before processing of the next message by the same actor.</li>
</ol>


<p>My framework makes these guarantess too.</p>

<ol>
<li>The dispatchId send rule: the send of the message to a dispatchId happens before the receive of that message by the same dispatchId.</li>
</ol>


<p> Proof:</p>

<ul>
<li> WorkStealingDispatcher: CHM hash-bucket locks and volatile reads ensure safe publication and happens-before guarantees;</li>
<li> ThreadBoundHashDispatcher: ConcurrentLinkedHashMap locks ensure safe publication and happens-before guarantees;</li>
<li>The dispatchId subsequent processing rule: processing of one message happens before processing of the next message by the same dispatchID.</li>
</ul>


<p> Proof:</p>

<ul>
<li> WorkStealingDispatcher: ConcurrentHashMap.compute is atomic by the contract and CompletableFuture&rsquo;s ordered chain ensures this;</li>
<li> ThreadBoundHashDispatcher: Java&rsquo;s ConcurrentLinkedHashMap ensures this;</li>
</ul>


<h2><strong>At last, the microbenchmarks</strong></h2>

<p>Benchmarks were written on JMH framework for JDK 7 and 8 separately and run on iMac Core i5 CPU @ 2.50GHz (4 cores) 8 GB, Yosemite OS. All the benchmark work with an empty Runnable synthetic task to mitigate side-effects.</p>

<p>I&rsquo;ve attached here 2 graphs for comparison of performance of JDK 7 and JDK 8 algorithms, respectively, based on random dispatchIds over a finite set.
For more thorough analysis, see <a href="https://github.com/vibneiro/dispatching/blob/master/README.md">the Dispatch Benchmarks on Github</a>. The trends don&rsquo;t differ much from test to test within a single Java-version, which proves eviction overhead (Bounded caching) of Weak-values to be neglible for these tests.</p>

<p><strong>Tests for Benchmarking:</strong></p>

<ol>
<li>A single dispatch-queue: putting new tasks always to the same dispatchId.</li>
<li>Counting dispatchId: one-off queue of size = 1 per task, that is dispatchId is incremented by 1 for new task.</li>
<li>Randomly filled set of queues with a size = 32768.</li>
</ol>


<p><strong>Benchmarking details:</strong></p>

<ul>
<li> Measuring a throughput (ops/s)</li>
<li> 32 user threads for all 3 tests;

<ul>
<li>Purpose: analyze contention impact on concurrent data-structures.</li>
</ul>
</li>
<li> 2 types of ExecutorService { ThreadPoolExecutor, ForkJoinPool };

<ul>
<li>Purpose: analyze the impact of 2 different executors on throughput.</li>
</ul>
</li>
</ul>


<p><strong>Caffeine</strong>
JDK 8 benchmarks have an additional test with Caffeinated cache which is a robust data structure that won my benchmarking tests, and can be used in the dispatching as well.</p>

<p><strong>JDK 8: 1.8.0_45</strong></p>

<p><img src="https://cloud.githubusercontent.com/assets/3040823/8034389/e25c08fc-0def-11e5-84dd-b95140376a46.png" alt="1. Java Version: 1.8.0_45" /></p>

<p><strong>JDK 7: 1.7.0._71</strong></p>

<p><img src="https://cloud.githubusercontent.com/assets/3040823/8080802/2c58486a-0f78-11e5-9e69-cb505e8df29d.png" alt="2. Java Version: 1.7.0_71" /></p>

<p>Note: A Caffeine works with JDK 8+, so there&rsquo;s no its benchmark here.</p>

<p><strong>Results: </strong></p>

<p>As can be seen, after introducing significant <a href="http://openjdk.java.net/jeps/155">updates</a> to Java 8, ForkJoinPool is a way more scalable, including ConcurrentHashMap changes compared to JDK 7.</p>

<h2>Conclusion</h2>

<p>I studied some parts of Caffeine&rsquo;s cache design under the hood. There are advanced techniques (e.g. eventually-consistent multithreaded datastructures, Stripe64 and full rewrite of ConcurrentHashMap proves to be very efficient)! It was fun to make some research, I believe it definetely deserves another post.</p>

<p>It showed very good results on the majority of <a href="https://github.com/vibneiro/dispatching">JMH performance benchmarks</a> compared to my implementations under similar parameters, considering working weak-values.
I decided not to remove <a href="https://github.com/vibneiro/dispatching/blob/master/dispatch-java-8/src/main/java/vibneiro/dispatchers/ThreadBoundHashDispatcher.java">ThreadBoundHashDispatcher</a> from the code though, as one might potentially have some benefits for some rare cases.</p>

<p>See <a href="https://github.com/vibneiro/dispatching">the code on Github</a> for more research, if interested.</p>

<p>By the way! Here&rsquo;s <a href="https://github.com/vibneiro/dispatching/blob/master/dispatch-java-7/src/main/java/vibneiro/dispatchers/WorkStealingDispatcher.java">a backport of Dispatcher to JDK 7</a> translated with Guava&rsquo;s ListenableFuture. I needed it for my project, despite that JDK 7 is not supported officialy anymore.</p>

<p>Hope this helps,</p>

<p>Ivan</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Toughest Backtracking Problems in Algorithmic Competitions]]></title>
    <link href="http://vibneiro.github.io/2015/02/05/toughest-backtracking-problems-in-algorithmic-competitions/"/>
    <updated>2015-02-05T14:53:05+03:00</updated>
    <id>http://vibneiro.github.io/2015/02/05/toughest-backtracking-problems-in-algorithmic-competitions</id>
    <content type="html"><![CDATA[<p><a href="https://ivoroshilin.files.wordpress.com/2015/02/backtrack.png"><img src="https://ivoroshilin.files.wordpress.com/2015/02/backtrack.png" alt="backtrack" /></a></p>

<h2><strong>TL;DR</strong></h2>

<p>In algorithmic competitions there are frequently problems that can be attacked with <a href="//en.wikipedia.org/wiki/Maze_generation_algorithm">recursive backtracking algorithms</a>) - a well-known approach to traverse <a href="//en.wikipedia.org/wiki/Depth-first_search">a search tree</a>). Usually, it is good smell, if there&rsquo;s a goal to analyze all existing combinations of a problem. And, of course, there needs to be the right strategy to meet time limits (e.g. prune it). Here, I&rsquo;ve decided to talk about a few very interesting backtracking problems I came across. I touch on a backtracking approach to develop in competitors, but bear in mind that, not trying to solve a problem by yourself, seeing the answer up front is a waste of time. Furthermore, this is an advanced level, if you haven&rsquo;t practiced a recursive backtracking or DFS, please spend some time on basic backtracking problems and come back.</p>

<h3><strong>1. Chess Puzzler</strong></h3>

<p><a href="https://ivoroshilin.files.wordpress.com/2015/02/chess.jpg"><img src="https://ivoroshilin.files.wordpress.com/2015/02/chess.jpg?w=300" alt="chess" /></a></p>

<p>This is quite an interesting problem I&rsquo;ve ever come across, solving it you realize some very important uses cases to consider like memory limits, recursion, combinatorics and optimization techniques. I&rsquo;ve seen a chess problem in Skiena&rsquo;s  algorithmic book some time ago, but as turned out, this one is very different.</p>

<h4><strong>Problem Statement:</strong></h4>

<p>The problem is to find all distinct layouts of a set of normal chess pieces on a chess board with dimensions MxN where none of the pieces is in a position to take any of the others. Assume the color of the piece does not matter, and that there are no pawns among the pieces.</p>

<p>Write a program which takes as input:</p>

<ul>
<li><p>  The dimensions of the board: M, N.</p></li>
<li><p>  The number of pieces of each type (King, Queen, Bishop, Rook and Knight) to try and place on the board.</p></li>
</ul>


<p>As output, the program should yield the number of distinct layouts for which all of the pieces can be placed on the board without threatening each other.</p>

<h4><strong>Solution:</strong></h4>

<p>We represent each piece as: &ldquo;K&rdquo; - King &ldquo;N&rdquo; - Knight &ldquo;Q&rdquo; - Queen &ldquo;R&rdquo; - Rook &ldquo;B&rdquo; - Bishop M - Horizontal size of the board N - Vertical size of the board S - is a set of remaining pieces. For example: Input: 3×3 board containing 2 Kings and 1 Rook, that is S = [K,K,R]. Answer: 4 layouts.</p>

<p><a href="https://ivoroshilin.files.wordpress.com/2015/02/layouts.png"><img src="https://ivoroshilin.files.wordpress.com/2015/02/layouts.png?w=300" alt="layouts" /></a></p>

<p>Since we need to find all possible layouts of a chessboard, it can be solved with a recursive backtracking as follows. We take the next piece from S and calculate for it all possible freeSquares on the chess board. Next, by iterating in a loop over freeSquares for current piece, we try to put it in all possible freeSquares. Each loop-step is a potential solution (layout) calls itself recursively by trying to put the next piece for current chess board and so forth until there are no pieces left or freeSquares is empty. Once a piece is placed on the board, we update the set of the free squares by subtracting a set of squares threatened by this piece. In case the set of free squares is empty and there are still any remaining pieces not on the board, there&rsquo;s no solution to this combination and the recursive function backtracks to the upper level in the recursive tree trying the next loop-step. Thereby, we loop over all steps and stop traversing by pruning impossible configuration in advance - as simple as this. There could be some arithmetic optimization with a number of threatened squares for each piece type by taking into account all remaining pieces to be put on the board and number of free squares, calculated in one go. Since the time limit in this problem was 20 mins to solve, I ditched an optimization. Undoubtedly, my solution can be drastically improved by cutting the search tree even more, and hence I leave this to the reader. Moreover you might want to parallelize this recursive task.</p>

<p>Finishing touch, namely what to do about duplicated pieces like 3 queens or 2 knights etc. Honestly, I spent a great deal of time on this while solving. The thing is that, duplicates are interchangeable in terms of different combinations on the chessboard. For instance, for a board of 1x2 length with free squares [x:1,y:1][x:1,y:2], 2 queens can be placed as [Q1][Q2] or [Q2][Q1] yielding 2 different combinations. A simple solution is to put at once all pieces of one type inside a loop-step. From combinatorics, we can enumerate all C(n, k) unique combinations (aka n choose k) in a single loop. Because we recurse, I created a <a href="https://github.com/vibneiro/Combinatorics/blob/master/Combinations.groovy">utility function</a> wrapped around with a standard java iterator which doesn&rsquo;t have to calculate all combinations up front, rather it traverses them lazily by calculating the next one on the fly. The reason for this was a memory taken on each level of the recursion stack to keep an array of all combinations. E.g. C(n, k) = C(1000,5) results into 8,250,291,250,200 elements. There were also some minor issues with Groovy not being able to correctly calculate a difference between 2 lists of coordinate-pairs. Thanks to guys on <a href="http://stackoverflow.com/">stackoverflow </a>who quickly replied with a <a href="http://stackoverflow.com/questions/27216832/groovy-language-how-to-get-difference-between-two-lists-of-pairs">workaround</a>. The full working code  is now available on <a href="https://github.com/vibneiro/ChessBoardSolver">GitHub</a>. If somebody of you have an idea to optimize it somehow, please comment one at the end of this post!</p>

<h3><strong>2. To backtrack or not, that&rsquo;s the question: Meet &ldquo;Mine Sweeper Master&rdquo; from Google code jam 2014</strong></h3>

<p><a href="https://ivoroshilin.files.wordpress.com/2015/02/minesweeper.png"><img src="https://ivoroshilin.files.wordpress.com/2015/02/minesweeper.png" alt="minesweeper" /></a></p>

<p>A tricky and simple at the same time problem was posed last year on Google Code Jam in qualification round - a famous <a href="https://code.google.com/codejam/contest/2974486/dashboard#s=p2">Mine Sweeper master</a>. Yes, the one that comes with Windows operating system - I bet, most of you are aware of! It&rsquo;s well-known solving minesweeper is<strong> NP-complete.</strong> But conditions of the problem don&rsquo;t require you to do that (Please read a problem statement before proceeding).</p>

<p>Solving it with a backtracking is the wrong way, as you are not required to analyze all configurations. The catch is that any correct result is a solution (read carefully a problem  statement)! And thus, you don&rsquo;t have to attack it with backtracking as this pattern is quite costly, aimed at getting all possible solutions. It is possible, but you won&rsquo;t pass the large set most likely. Hence, the simplest idea is to start at (0,0) - upper-left corner and fill an area of <code>N</code> cells  with non-mine space from left to right and top to bottom - line-by-line. Further, fill the rest with mines. Clicking the (0,0) cell should reveal if this is a good solution. If (0,0) is not a mine - we have won. If the square contains a 0, repeat this recursively for all the surrounding squares.</p>

<p>There are also a number of important corner cases to consider for this approach:</p>

<p><strong>Single non-mine</strong></p>

<p>If <code>N=1</code>, any configuration is a correct solution.</p>

<p><strong>Single row or single column</strong></p>

<pre><code>If &lt;code&gt;R=1&lt;/code&gt;, simply fill in the &lt;code&gt;N&lt;/code&gt; non-mines from left-to-right. If &lt;code&gt;C=1&lt;/code&gt;, fill &lt;code&gt;N&lt;/code&gt; rows with a (single) non-mine.
</code></pre>

<p><strong>Too few non-mines</strong></p>

<pre><code>If &lt;code&gt;N&lt;/code&gt; is even, it must be &gt;= 4. 
If &lt;code&gt;N&lt;/code&gt; is odd, it must be &gt;= 9. Also, &lt;code&gt;R&lt;/code&gt; and &lt;code&gt;C&lt;/code&gt; must be &gt;= 3.

Otherwise there's no solution.
</code></pre>

<p><strong>Can&rsquo;t fill first two rows</strong></p>

<pre><code>If &lt;code&gt;N&lt;/code&gt; is even and you can't fill at least two rows with non-mines, then fill the first two rows with &lt;code&gt;N / 2&lt;/code&gt; non-mines.   
If &lt;code&gt;N&lt;/code&gt; is odd and you can't fill at least two rows with non-mines and a third row with 3 non-mines, then fill the first two rows with &lt;code&gt;(N - 3) / 2&lt;/code&gt; non-mines and the third row with 3 non-mines.
</code></pre>

<p><strong>Single non-mine in the last row</strong></p>

<pre><code>If &lt;code&gt;N % C = 1&lt;/code&gt;, move the final non-mine from the last full row to the next row.
</code></pre>

<p>I was lazy to depict each one. As can be seen, there is bunch of special cases to consider to make this solution pass.</p>

<h3><strong>3. Another Chess Board Puzzler: &ldquo;King&rdquo; from Google Code Jam 2008</strong></h3>

<p>This is one of the toughest<a href="http://code.google.com/codejam/contest/32008/dashboard#s=p3"> problem</a>s from Google Code Jam. It differs in that <strong>no one solved it</strong> in global Code Jam rounds during the round in which it was posed. Algorithmic competitions is like sports, if you feel you can solve easier problems faster - go for it. Otherwise you&rsquo;re at risk of loosing the competition. Some day next time I will try to attack it too, and for now I say goodbye to  all of you.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Project Euler: A List of Interesting Problems]]></title>
    <link href="http://vibneiro.github.io/2014/09/15/project-euler-a-list-of-interesting-problems/"/>
    <updated>2014-09-15T10:17:39+04:00</updated>
    <id>http://vibneiro.github.io/2014/09/15/project-euler-a-list-of-interesting-problems</id>
    <content type="html"><![CDATA[<p><a href="https://ivoroshilin.files.wordpress.com/2014/09/euler.jpg"><img src="http://ivoroshilin.files.wordpress.com/2014/09/euler.jpg" alt="Euler" /></a></p>

<p>If you are not aware a website called <a href="http://projecteuler.net/">Project Euler</a> has hundreds of algorithmic problems. Despite that most of them are related to math it&rsquo;s a good resource to warm up/train your brain in coding. You can use any programming language that you want and track progress.</p>

<p>Here&rsquo;s a list of interesting Euler&rsquo;s problems in terms of diversity from my point of view with the aim to improve not only math but also programming skils (No/ Problem Titile):</p>

<p>11 - Largest product in a grid
12 - Highly divisible triangular number
15 - Lattice paths
24 - Lexicographic permutations
54 - Poker hands
59 - XOR decryption
62 - Cubic permutations
67 - Maximum path sum II
68 - Magic 5-gon ring
78 - Coin partitions
79 - Passcode derivation
81 - Path sum: two ways
86 - Cuboid route
94 - Almost equilateral triangles
96 - Sudoku
100 - Arranged probability
107 - Minimal network
109 - Darts
114 - Counting block combinations I
115 - Counting block combinations II
116 - Red, green or blue tiles
117 - Red, green, and blue tiles
145 - How many reversible numbers are there below one-billion?
148 - Exploring Pascal&rsquo;s triangle
150 - Searching a triangular array for a sub-triangle having minimum-sum
154 - Exploring Pascal&rsquo;s pyramid
165 - Intersections
166 - Criss Cross
181 - Investigating in how many ways objects of two different colours can be grouped
182 - RSA encryption
186 - Connectedness of a network
194 - Coloured Configurations
208 - Robot Walks
209 - Circular Logic
232 - The Race
267 - Billionaire
275 - Balanced Sculptures
280 - Ant and seeds</p>

<p>Note that it is highly recommended to solve all Euler&rsquo;s problems one by one because solving a previous problem has a clue to the next ones.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MinHash Algorithm or How to Quickly Find Similarities Among 2 Documents]]></title>
    <link href="http://vibneiro.github.io/2013/10/07/minhash-algorithm-or-how-to-quickly-find-similarities-among-2-documents/"/>
    <updated>2013-10-07T02:57:48+04:00</updated>
    <id>http://vibneiro.github.io/2013/10/07/minhash-algorithm-or-how-to-quickly-find-similarities-among-2-documents</id>
    <content type="html"><![CDATA[<p>MinHash is a technique from <a href="http://en.wikipedia.org/wiki/Locality_sensitive_hashing">Locality Sensitive Hashing</a> allowing to find similarities among 2 sets. This is a  buzzword frequently met in Data Mining  and Data Science fields of CS. What surprising is that this method was invented in 1997 and used in <a href="http://en.wikipedia.org/wiki/AltaVista">AltaVista</a> web-search engine back in the 90s to find similarities among web-documents and it also can be used to:</p>

<ul>
<li><p>Find duplicates</p></li>
<li><p>Near duplicate image detection</p></li>
<li><p>Near neighbor search</p></li>
</ul>


<p>Basically the algorithm can be applied to anything that can be presented by numbers.</p>

<p>Let&rsquo;s start with a bit of math from theory of probability and statistics.</p>

<p>Define a formula of two sets <em>A</em> and <em>B:</em></p>

<p><img src="http://upload.wikimedia.org/math/1/8/6/186c7f4e83da32e889d606140fae25a0.png" alt=" J(A,B) = |A \cap B|\over|A \cup B|." /></p>

<p>This is so-called  a <a href="http://en.wikipedia.org/wiki/Jaccard_index">Jaccard coefficient</a>.</p>

<p>Where: J ∈ [0..1]</p>

<p>j = 0 - if <em><em><em>A</em> ∩ </em>B = 0, that is 2 sets are disjoint meaning there are no similarities</em></p>

<p><em>j = 1 - if __A</em> ∩ <em>B</em> = A = <em>B, that is 2 sets are identical.</em>
__</p>

<p>A, B are more similar when their <strong>Jaccard coefficient</strong> is closer to 1.</p>

<p>This simple formula is cumbersome if the sets are quite large, e.g. 2 web-documents of more than 1MB in size. Ouch, that&rsquo;s too much. 1MB of text-data is <strong>1,048,576 characters </strong>provided that 1 ASCII char = 8 bits (of course for unicode charset it is greater).</p>

<p>Now that we understand a bit of theory let&rsquo;s try to apply hashing to Jaccard coefficient. Everywhere I hear hashing it always leads to randomized algorithms.</p>

<p>Ok, let&rsquo;s move on. The main idea is that similar objects hash to the same bucket. This follows from the fact that <strong>probability of collision higher for similar objects</strong>.</p>

<p>Here we give an example for 2 sets A and B but the algorithm can be applied to any number of sets.</p>

<ol>
<li><p>Essentially, we need to construct a set of independent hash functions &lt;h1,h2,h3,&hellip;hk> <strong>randomly</strong>.  <em>k</em> = O(1/ε2), ε > 0 such that the expected error of the estimate is at most ε. For example, 400 hashes would be required to estimate <em>J</em>(<em>A</em>,<em>B</em>) with an expected error less than or equal to .05. So, k can be varied to increase/decrease the likelihood of false negatives.</p></li>
<li><p>Next we initialize for each set A and B the <img src="http://www.toao.com/equations/49e83e4884bd478aecc7fb7e0a7e9477.png" alt="" /> value to infinity.</p></li>
<li><p>For each element s in both sets A and B we compute the element&rsquo;s hash:</p></li>
</ol>


<p><img src="http://www.toao.com/equations/8664800335406d60ca14c723421d994c.png" alt="" /> such as: If <img src="http://www.toao.com/equations/d3d634b0636790f7fd707ad50b85b0a5.png" alt="" /> then <img src="http://www.toao.com/equations/f08914f853c4fcd405dafd052d100c5a.png" alt="" />.</p>

<p>Eventually we should have <img src="http://www.toao.com/equations/49e83e4884bd478aecc7fb7e0a7e9477.png" alt="" /> for both sets A and B.</p>

<ol>
<li><p>If 2 sets A and B are similar then the probability P(  <img src="http://www.toao.com/equations/49e83e4884bd478aecc7fb7e0a7e9477.png" alt="" />A =  <img src="http://www.toao.com/equations/49e83e4884bd478aecc7fb7e0a7e9477.png" alt="" />B) = |<em>A</em> ∩ <em>B</em>| / |A U B|- is high and <strong>it</strong> <strong>is the actual Jaccard coefficient!</strong></p></li>
<li><p>We calculated  <img src="http://www.toao.com/equations/49e83e4884bd478aecc7fb7e0a7e9477.png" alt="" /> statistics to estimate how similar are these 2 sets. General formula is: Similarity = identical <img src="http://www.toao.com/equations/49e83e4884bd478aecc7fb7e0a7e9477.png" alt="" />s / k</p></li>
</ol>


<p>In real world this requires considering more thoroughly different parameters, hash-functions etc. However, to demonstrate the algorithm I wrote a simple java code:</p>

<p>[sourcecode language=&ldquo;java&rdquo;]
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.Random;
import java.util.Set;</p>

<p>public class LSHMinHash<T> {</p>

<pre><code>private final int hashes[];
private final int numOfHashes;
private final int numOfSets;
private final Set&lt;T&gt; setA;
private final Set&lt;T&gt; setB;
private final Map&lt;T, boolean[]&gt; matrix;
private final int[][] minHashes;

public LSHMinHash(double e, Set&lt;T&gt; setA, Set&lt;T&gt; setB){
    this.numOfHashes = (int)(1 / (e * e));
    this.numOfSets = 2;
    this.setA = setA;
    this.setB = setB;
    matrix = buildSetMatrix(setA, setB);
    minHashes = initMinHashes(numOfSets, numOfHashes);
    hashes = computeHashes(numOfHashes);
}

private Map&lt;T,boolean[]&gt; buildSetMatrix(Set&lt;T&gt; setA, Set&lt;T&gt; setB) {

    Map&lt;T,boolean[]&gt; matrix = new HashMap&lt;T,boolean[]&gt;();

    for(T element : setA){
        matrix.put(element, new boolean[] { true, false } );
    }

    for(T element : setB){
        if(matrix.containsKey(element)){
            matrix.put(element, new boolean[] { true, true } );
        }else if(!matrix.containsKey(element)){
            matrix.put(element, new boolean[] { false, true } );
        }
    }

    return matrix;
}

private int[][] initMinHashes(int numOfSets, int numOfHashes) {
    int[][] minHashes = new int[numOfSets][numOfHashes];

    for (int i = 0; i &lt; numOfSets; i++) {
        for (int j = 0; j &lt; numOfHashes; j++) {
            minHashes[i][j] = Integer.MAX_VALUE;
        }
    }
    return minHashes;
}

private int[] computeHashes(int numOfHashes) {
    int[] hashes = new int[numOfHashes];
    Random r = new Random(31);

    for (int i = 0; i &lt; numOfHashes; i++){
        int a = (int)r.nextInt();
        int b = (int)r.nextInt();
        int c = (int)r.nextInt();
        hashes[i] = (int)((a * (a * b * c &gt;&gt; 4) + a * a * b * c + c) &amp; 0xFFFFFFFF);
    }
    return hashes;
}

private void computeMinHashForSet(Set&lt;T&gt; set, int setIndex){
    int hashIndex = 0;

    for(T element : matrix.keySet()) {
        for (int i = 0; i &lt; numOfHashes; i++) {
            if(set.contains(element)) {
                int hashValue = hashes[hashIndex];
                if (hashValue &lt; minHashes[setIndex][hashIndex]) {
                    minHashes[setIndex][hashIndex] = hashValue;
                }
            }
        }
        hashIndex++;
    }
}

private double computeMinHash(int[][] minHashes, int numOfHashes) {
    int identicalMinHashes = 0;
    for (int i = 0; i &lt; numOfHashes; i++){
        if (minHashes[0][i] == minHashes[1][i]) {
            identicalMinHashes++;
        }
    }
    return (1.0 * identicalMinHashes) / numOfHashes;
}

public double findSimilarities() {
    computeMinHashForSet(setA, 0);
    computeMinHashForSet(setB, 1);
    return computeMinHash(minHashes, numOfHashes);
}

public static void main(String[] args){
    Set&lt;String&gt; setA = new HashSet&lt;String&gt;();
    setA.add("THIS");
    setA.add("IS ");
    setA.add("THE");
    setA.add("CASE");

    Set&lt;String&gt; setB = new HashSet&lt;String&gt;();
    setB.add("THAT");
    setB.add("IS ");
    setB.add("THE");
    setB.add("CASE");

    double errorFactor = 0.001;

    LSHMinHash&lt;String&gt; minHash = new LSHMinHash&lt;String&gt;(errorFactor, setA, setB);
    System.out.println(minHash.findSimilarities());
}
</code></pre>

<p>}
[/sourcecode]</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How Automatic Sharding Works or Consistent Hashing Under the Hood]]></title>
    <link href="http://vibneiro.github.io/2013/07/15/distributed-caching-under-consistent-hashing/"/>
    <updated>2013-07-15T12:25:09+04:00</updated>
    <id>http://vibneiro.github.io/2013/07/15/distributed-caching-under-consistent-hashing</id>
    <content type="html"><![CDATA[<h2>Preface</h2>

<p>Here we&rsquo;re going to talk primarily about Consistent hashing. This technique involves such concepts as adaptive load balancing, routing, partitioning in distributed computing. There are many articles on the internet on this technique (refer to the list of references for some of them) but I haven&rsquo;t found information about how and where to keep the ring of hashes, thus I&rsquo;ve decided to describe some options with pros and cons. In order to make this post more clear for a wider audience I will first try to write a brief introduction of what this is all about and tell about <strong>the ring storage strategies</strong> at the end of this issue. So if you&rsquo;re already familiar with the algorithm you may want to skip over the main stuff and move on to the last chapter for pros and cons of descibed approaces.</p>

<h3>Distributed cache and straightforward uniform load balancing</h3>

<p>Key-value stores are extremely fast in single search-queries. A very popular one is a distributed hash table (DHT) kept in a fully decentralized manner, and thus particularly adapted to unstable networks where nodes can leave or join at any moment. Note that DHT is not suitable for range-queries albeit and I will probably write a separate post about special data structures responsible for that. Now let&rsquo;s consider a classic case - you have a cluster of cache-servers where you load-balance a huge data set uniformly. To be able to determine on which node a pair &lt;key, value> should be kept we use a simple hash-mapping:</p>

<blockquote>Cache machine = hash(o) mod n where: n - number of machines in a cluster and o is an object to put/lookup.</blockquote>


<p>What happens when a number of machines changes at runtime? You might add/remove a number of machines in a cluster for e.g. scalability reasons, a failure or whatever.  The change triggers moving almost all objects to new locations due to rehashing.  Each key-value pair will get reallocated completely across the cluster. You’ll end up moving a fraction<strong> n/(n+1)</strong> of your data to new machines. Indeed, this fact degrades all of the advantages of distributed hash tables. We need somehow to avoid this messy remapping. This is where consistent hashing comes in.</p>

<h2>Consistent hashing</h2>

<p>The main idea is to hash both data ids and cache-machines to a numeric range using the same hash-function. E.g. in Java a primitive type int has a number range of values between -231 to 231-1.  Assume the interval is [0,  231-1] for simplicity (java primitives cannot be unsigned). Now let&rsquo;s join starting and ending points together of this interval to create a ring so the values wrap around. We do not have 231 -1 available servers, the large size of the ring being merely intended to avoid collisions. As a hash function a good choise is either be e.g. MD5 or SHA-1 algorithm. As a machine&rsquo;s number we can take its IP-address and apply that hash function to it. By taking from the result the first 8 bytes we can map it to our ring [0,231-1].</p>

<p><a href="http://ivoroshilin.files.wordpress.com/2013/07/ring_range1.png"><img src="http://ivoroshilin.files.wordpress.com/2013/07/ring_range1.png" alt="ring_range" /></a></p>

<p>Both the nodes and the keys are mapped to the same range on the ring. Ok, now we need to understand how to identify on this ring which data ids belong to which server&rsquo;s IP. It&rsquo;s really simple, we just move clockwise starting from zero (starting point on the ring) following the main rule of consistent hashing: If IP-n1 and IP-n2 are 2 adjacent nodes on the ring all data ids on the ring between them belong to IP-n1. That&rsquo;s it. <a href="http://ivoroshilin.files.wordpress.com/2013/07/ring_mapping1.png"><img src="http://ivoroshilin.files.wordpress.com/2013/07/ring_mapping1.png" alt="ring_mapping" /></a></p>

<p>As depicted: { Id1, Id2, Id3} ∈ IP-3; {Id4} ∈ IP-1; ∅ ∈ IP-2.</p>

<p><strong>Conclusion:</strong> Using consistent hashing we do not need to rehash the whole data set. Instead, the new server takes place at a position determined by the hash value on the ring, and part of the objects stored on its successor must be moved. The reorganization is local, as all the other nodes remain unaffected. if you add a machine to the cluster, only the data that needs to live on that machine is moved there; all the other data stays where it is. Because the hash function remains unaffected, the scheme maintains its consistency over the successive evolutions of the network configuration. Like naive hashing, consistent hashing spreads the distributed dictionary almost evenly across the cluster. One point to mention is what happens when a node goes down due to some disaster. In this case consistent hashing alone doesn&rsquo;t meet our requirements of reliability due to loss of data. Therefore there should definetely be replication and high availability which is feasible and out of scope of this introduction. You may want to find good references at the end of these article to find out more.</p>

<h3>Problems with pure consistent hashing</h3>

<p>In a nutshell, the basic consistent hashing has the following problems:</p>

<ul>
<li><p>There is a huge amount of data to be rehashed.</p></li>
<li><p>A node picking a range of keys results in one node potentially carrying a larger keyspace than others, therefore still creating disbalance.</p></li>
<li><p>Leaving/Joining a ring leads to disbalance of data.</p></li>
<li><p>A more powerful machine needs to process more data than others.</p></li>
<li><p>A fraction of data to be moved is less unpredictable and much higher.</p></li>
</ul>


<p><strong>Virtual nodes </strong>solve these issues.</p>

<h2>Virtual nodes come to the rescue</h2>

<p>Virtual nodes <strong>minimize changes</strong> <strong>to a node&rsquo;s assigned range</strong> by a number of smaller ranges to a single node. In other words, amount of data to be moved from one physical node to others is minimized. Let&rsquo;s split a real node into a number of virtual nodes. The idea is to build equally-sized subintervals (partitions) for each real server on the ring by dividing the hash-space into P evenly sized partitions, and assign P/N partitions per host. When a node joins/leaves all data from partitions of all real servers are uniformly get assigned to a new server and given back to remaining ones respectively. The number of virtual nodes is picked once during building of the ring  and never changes over the lifetime of the cluster. This ensures that each node picks equal size of data from the full data set, that is P/N and thus our data now are distributed more uniformly. This enforces that the number of virtual nodes must be much higher than the number of real ones.</p>

<p><a href="http://ivoroshilin.files.wordpress.com/2013/07/ring_hashing.png"><img src="http://ivoroshilin.files.wordpress.com/2013/07/ring_hashing.png" alt="ring_hashing" /></a></p>

<p>Here&rsquo;s a pretty simple java-code of consistency ring&rsquo;s  with virtual nodes.</p>

<p>[sourcecode language=&ldquo;java&rdquo;]
public class Ring {</p>

<pre><code>private SortedMap&lt;Long, T&gt; ring = new TreeMap&lt;Long, T&gt;();
private HashMap&lt;String, T&gt; nodeMap = new HashMap&lt;String, T&gt;();
private MD5Hash hash = new MD5Hash();
private vNodeCount;

public Ring(int vnodeCount, Collection pNodes) {

    this.vnodeCount = vnodeCount;

    for (T pNode : pNodes) {
        addNode(ring, nodeMap, pNode, vnodeCount);
    }
}

private void addNode(T pNode, int vnodeCount) {
    for (int i = 0; i &lt; vnodeCount; i++) {
        ring.put(hash.hash(pNode.toString() + i), pNode);
    }
}

    public void removeNode(T node, int vnodeCount) {
      for (int i = 0; i &lt; vnodeCount; i++) {
        ring.remove(hash.hash(pNode.toString() + i));
      }
    }

private T getNodeByObjectId(String objectId) {

    long hashValue = hash.hash(objectId);

    if (!ring.containsKey(hashValue)) {
        SortedMap&lt;Long, T&gt; tailMap = ring.tailMap(hashValue);
        hashValue = tailMap.isEmpty() ? ring.firstKey() : tailMap.firstKey();
    }

    return ring.get(hashValue);
}

private static class MD5Hash {
    MessageDigest instance;

    public MD5Hash() {
        try {
            instance = MessageDigest.getInstance("MD5");
        } catch (NoSuchAlgorithmException e) {
        }
    }

    long hash(String key) {
        instance.reset();
        instance.update(key.getBytes());
        byte[] digest = instance.digest();

        long h = 0;
        for (int i = 0; i &lt; 4; i++) {
            h &lt;&lt;= 8;
            h |= ((int) digest[i]) &amp; 0xFF;
        }
        return h;
    }
};
</code></pre>

<p>}
[/sourcecode]</p>

<h2>Strategies to keep a data structure of the ring and their pros and cons</h2>

<p>There are a few options on where to keep ring&rsquo;s data structure:</p>

<ul>
<li><p><strong>Central point of coordination:</strong> A dedicated machine keeps a ring and works as a <strong>central load-balancer</strong> which routes request to appropriate nodes.</p></li>
<li><p>Pros: Very simple implementation. This would be a good fit for not a dynamic system having small number of nodes and/or data.</p></li>
<li><p>Cons: A big drawback of this approach is scalability and reliability. Stable distributed systems don&rsquo;t have a <strong>single poing of failure.</strong></p></li>
<li><p><strong><strong>No central point of coordination - full duplication:</strong> </strong>Each node keeps a full copy of the ring. Applicable for stable networks. This option is used e.g. in Amazon Dynamo.</p></li>
<li><p>Pros: Queries are routed in one hop directly to the appropriate cache-server.</p></li>
<li><p>Cons: Join/Leave of a server from the ring  requires notification/amendment of all cache-servers in the ring.</p></li>
<li><p><strong>No central point of coordination - partial duplication: </strong>Each node keeps a partial copy of the ring. This option is direct implementation of CHORD algorithm. In terms of DHT each cache-machine has its predessesor and successor and when receiving a query one checks if it has the key or not. If there&rsquo;s no such a key on that machine, a mapping function is used to determine which of its neighbors (successor and predessesor) has the least distance to that key. Then it forwards the query to its neighbor thas has the least distance. The process continues until a current cache-machine finds the key and sends it back.</p></li>
<li><p>Pros: For highly dynamic changes the previous option is not a fit due to heavy overhead of gossiping among nodes. Thus this option is the choice in this case.</p></li>
<li><p>Cons: No direct routing of messages. The complexity of routing a message to the destination node in a ring is O(lg N).</p></li>
</ul>


<h3>Current trends in consistent hashing</h3>

<p>There is a huge boom nowadays of new products that implement this technique. Some of them are: Dynamo, Riak, Cassandra, MemCached, Voldemort, CouchDB, Oracle Coherence, Trackerless Bit-Torrent networks, Web-caching frameworks, Content distribution networks.</p>

<h2>References</h2>

<ul>
<li><p><a href="http://java.dzone.com/articles/simple-magic-consistent">The Simple Magic of Consistent Hashing</a></p></li>
<li><p><a href="http://michaelnielsen.org/blog/consistent-hashing/">Consistent hashing</a></p></li>
<li><p><a href="https://weblogs.java.net/blog/tomwhite/archive/2007/11/consistent_hash.html">Consistent hashing by Tom White</a></p></li>
<li><p><a href="http://techspot.zzzeek.org/2012/07/07/the-absolutely-simplest-consistent-hashing-example">The Absolutely Simplest Consistent Hashing Example</a></p></li>
<li><p><a href="http://cloudfundoo.wordpress.com/2012/05/28/distributed-hash-tables-and-consistent-hashing/">Distributed Hash Tables and Consistent Hashing</a></p></li>
<li><p><a href="http://www.acunu.com/2/post/2012/07/virtual-nodes-strategies.html">Virtual Nodes strategies</a> <a href="http://www.tomkleinpeter.com/2008/03/17/programmers-toolbox-part-3-consistent-hashing/">Programmer&rsquo;s toolbox</a></p></li>
<li><p><a href="http://www.tomkleinpeter.com/2008/03/17/programmers-toolbox-part-3-consistent-hashing/">Programmer&rsquo;s toolbox: consistent hashing</a></p></li>
<li><p><a href="http://offthelip.org/?p=149">Distributed Hash Tables</a></p></li>
<li><p><a href="http://www.lastfm.ru/user/RJ/journal/2007/04/10/rz_libketama_-_a_consistent_hashing_algo_for_memcache_clients">libketama - a consistent hashing algo for memcache clients</a></p></li>
<li><p><a href="http://www.sarmady.com/siamak/papers/dht-soft-300807.pdf">A Peer-to-Peer Dictionary Using Chord DHT</a></p></li>
<li><p><a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf">Dynamo: Amazon’s Highly Available Key-value Store</a></p></li>
<li><p><a href="http://greg.brim.net/page/building_a_consistent_hashing_ring.html">Building a Consistent Hashing Ring</a></p></li>
</ul>

]]></content>
  </entry>
  
</feed>
